{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Kneighbors.ipynb","provenance":[],"authorship_tag":"ABX9TyPrKdSEe4ky4/rb4hy0CgLi"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SGUEvvZLBj-V","executionInfo":{"status":"ok","timestamp":1626049205429,"user_tz":-540,"elapsed":7885,"user":{"displayName":"천영성","photoUrl":"","userId":"06905110897473075189"}},"outputId":"6901bb96-6ff1-41e5-ae9a-073673162105"},"source":["!apt -qq -y install fonts-nanum\n"," \n","import matplotlib.pyplot as plt\n","import matplotlib.font_manager as fm\n"," \n","fontpath = '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf'\n","font = fm.FontProperties(fname=fontpath, size=10)\n","fm._rebuild()\n"," \n","# 그래프에 retina display 적용\n","%config InlineBackend.figure_format = 'retina'\n"," \n","# Colab 의 한글 폰트 설정\n","plt.rc('font', family='NanumBarunGothic') "],"execution_count":1,"outputs":[{"output_type":"stream","text":["The following NEW packages will be installed:\n","  fonts-nanum\n","0 upgraded, 1 newly installed, 0 to remove and 39 not upgraded.\n","Need to get 9,604 kB of archives.\n","After this operation, 29.5 MB of additional disk space will be used.\n","Selecting previously unselected package fonts-nanum.\n","(Reading database ... 160815 files and directories currently installed.)\n","Preparing to unpack .../fonts-nanum_20170925-1_all.deb ...\n","Unpacking fonts-nanum (20170925-1) ...\n","Setting up fonts-nanum (20170925-1) ...\n","Processing triggers for fontconfig (2.12.6-0ubuntu2) ...\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LQmVK5zJFZT7","executionInfo":{"status":"ok","timestamp":1626049236314,"user_tz":-540,"elapsed":5063,"user":{"displayName":"천영성","photoUrl":"","userId":"06905110897473075189"}},"outputId":"97e34313-6bb8-479a-b277-9770b3359b12"},"source":["!pip install mglearn\n"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting mglearn\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/65/38/8aced26fce0b2ae82c3c87cd3b6105f38ca6d9d51704ecc44aa54473e6b9/mglearn-0.1.9.tar.gz (540kB)\n","\r\u001b[K     |▋                               | 10kB 21.1MB/s eta 0:00:01\r\u001b[K     |█▏                              | 20kB 28.4MB/s eta 0:00:01\r\u001b[K     |█▉                              | 30kB 23.3MB/s eta 0:00:01\r\u001b[K     |██▍                             | 40kB 19.0MB/s eta 0:00:01\r\u001b[K     |███                             | 51kB 15.4MB/s eta 0:00:01\r\u001b[K     |███▋                            | 61kB 13.8MB/s eta 0:00:01\r\u001b[K     |████▎                           | 71kB 13.3MB/s eta 0:00:01\r\u001b[K     |████▉                           | 81kB 14.6MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 92kB 13.6MB/s eta 0:00:01\r\u001b[K     |██████                          | 102kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 112kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 122kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 133kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 143kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████                       | 153kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 163kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 174kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████                     | 184kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 194kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 204kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 215kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 225kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 235kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 245kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 256kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 266kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 276kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 286kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 296kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 307kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 317kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 327kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 337kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 348kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 358kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 368kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 378kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 389kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 399kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 409kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 419kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 430kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 440kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 450kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 460kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 471kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 481kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 491kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 501kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 512kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 522kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 532kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 542kB 13.5MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mglearn) (1.19.5)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from mglearn) (3.2.2)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from mglearn) (0.22.2.post1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from mglearn) (1.1.5)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from mglearn) (7.1.2)\n","Requirement already satisfied: cycler in /usr/local/lib/python3.7/dist-packages (from mglearn) (0.10.0)\n","Requirement already satisfied: imageio in /usr/local/lib/python3.7/dist-packages (from mglearn) (2.4.1)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from mglearn) (1.0.1)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mglearn) (2.4.7)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mglearn) (2.8.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mglearn) (1.3.1)\n","Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->mglearn) (1.4.1)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->mglearn) (2018.9)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler->mglearn) (1.15.0)\n","Building wheels for collected packages: mglearn\n","  Building wheel for mglearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for mglearn: filename=mglearn-0.1.9-py2.py3-none-any.whl size=582638 sha256=c63c6993f1459e6e1dc78eea53d849e0b7c10ef8c3d9407edcb543086d34807c\n","  Stored in directory: /root/.cache/pip/wheels/eb/a6/ea/a6a3716233fa62fc561259b5cb1e28f79e9ff3592c0adac5f0\n","Successfully built mglearn\n","Installing collected packages: mglearn\n","Successfully installed mglearn-0.1.9\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"zWGHVqz0Ftnq"},"source":["##K최근접 이웃 알고리즘 "]},{"cell_type":"markdown","metadata":{"id":"VBkqsU34qj51"},"source":["지도 학습 (Supervised Learning)\n","- 데이터에 대한 Label(명시적인 답)이 주어진 상태에서 컴퓨터를 학습시키는 방법. \n","\n","비지도 학습 (Unsupervised Learning)\n","- 데이터에 대한 Label(명시적인 답)이 없는 상태에서 컴퓨터를 학습시키는 방법.\n","- 데이터의 숨겨진 특성이나 구조를 파악하는데 사용.\n"]},{"cell_type":"markdown","metadata":{"id":"Y_xNAGonFzLl"},"source":["분류 (Classification)\n","- 미리 정의된 여러 클래스 레이블 중 하나를 예측하는 것.\n","- 속성 값을 입력, 클래스 값을 출력으로 하는 모델\n","- 붓꽃(iris)의 세 품종 중 하나로 분류, 암 분류 등. \n","- 이진분류, 다중 분류 등이 있다.\n"]},{"cell_type":"code","metadata":{"id":"_U3ldpyPF-e3"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YbqjV135rRz3"},"source":["일반화, 과대적합, 과소적합\n","\n","일반화 (Generalization)\n","- 훈련 세트로 학습한 모델이 테스트 세트에 대해 정확히 예측 하도록 하는 것 .\n","\n","과대적합 (Overfitting)\n","- 훈련 세트에 너무 맞추어져 있어 테스트 세트의 성능 저하.\n","\n","과소적합 (Underfitting)\n","- 훈련 세트를 충분히 반영하지 못해 훈련 세트, 테스트 세트에서 모두 성능이 저하.\n"]},{"cell_type":"markdown","metadata":{"id":"rtmLE4G1GCuz"},"source":["<center>\n"," <img src=\"https://image.slidesharecdn.com/2-171030145527/95/2supervised-learningepoch21-9-1024.jpg?cb=1509375471\" alt=\"과대적합\" width=\"40%\" />\n","\n","</center>"]},{"cell_type":"markdown","metadata":{"id":"pHSSEHA9GE9P"},"source":["<center>\n"," <img src=\"https://image.slidesharecdn.com/2-171030145527/95/2supervised-learningepoch21-10-1024.jpg?cb=1509375471\" alt=\"과소적합\" width=\"60%\" />\n","\n","</center>"]},{"cell_type":"markdown","metadata":{"id":"dDSFpesGGIGM"},"source":["***일반화 성능이 최대화 되는 모델을 찾는 것이 목표***\n","\n","과대적합 (Overfitting)\n","- 너무 상세하고 복잡한 모델링을 하여 훈련데이터에만 과도하게 정확히 동작하는 모델.\n","\n","과소적합 (Underfitting)\n","- 모델링을 너무 간단하게 하여 성능이 제대로 나오지 않는 모델.\n"]},{"cell_type":"markdown","metadata":{"id":"OBlGFNWCHhhZ"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"9-n3Dy3PGMmt"},"source":["모델 복잡도 곡선\n","\n","\n","<center>\n"," <img src=\"https://tensorflowkorea.files.wordpress.com/2017/06/fig2-01.png\" alt=\"모델 복잡도 곡선\" width=\"60%\" />\n","\n","</center>\n","\n"]},{"cell_type":"markdown","metadata":{"id":"xen0fO1oGTDd"},"source":["해결방법\n","\n","- 주어진 훈련데이터의 다양성이 보장되어야 한다 (다양한 데이터포인트를 골고루 나타내야 한다)\n","- 일반적으로 데이터 양이 많으면 일반화에 도움이 된다.\n","- 그러나 편중된 데이터를 많이 모으는 것은 도움이 되지 않는다.\n","- 규제(Regularization)을 통해 모델의 복잡도를 적정선으로 설정한다.\n"]},{"cell_type":"markdown","metadata":{"id":"ZlFUGEdnGYV5"},"source":["##K-Nearest Neighbors"]},{"cell_type":"markdown","metadata":{"id":"hKp0zZ3JGlkv"},"source":["- 새로운 데이터 포인트와 가장 가까운 훈련 데이터셋의 데이터  포인트를 찾아 예측\n"]},{"cell_type":"markdown","metadata":{"id":"S9hb8eC0Gqeq"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"Nq47kaWj0i-Q"},"source":["- 입력 값과 k개의 가까운 점이 있다고 가정할 때 그 점들이 어떤 라벨과 가장 비슷한지 (최 근접 이웃)\n","판단하는 알고리즘\n","\n","- 매개 변수 : 데이터 포인트 사이의 거리를 재는 방법 (일반적으로 유클리디안 거리 사용), 이웃의 수\n"," - 장점 : 이해하기 쉬운 모델, 약간의 조정으로 좋은 성능\n"," - 단점 : 훈련 세트가 크면 속도가 느림, 많은 특성을 처리하기 힘듬"]},{"cell_type":"code","metadata":{"id":"KOxtjn4hGjVR"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mmMiDYyhITjX"},"source":["<center>\n"," <img src=\"https://tensorflowkorea.files.wordpress.com/2017/06/2-4.png?w=625\" alt=\"1-최근접 이웃 모델\" width=\"60%\" />\n","\n","1-최근접 이웃 모델\n","\n"," <img src=\"https://tensorflowkorea.files.wordpress.com/2017/06/2-5.png?w=768\" alt=\"3-최근접 이웃 모델\" width=\"60%\" />\n","\n"," 3-최근접 이웃 모델\n","\n","</center>\n"]},{"cell_type":"markdown","metadata":{"id":"c42ZH4ZdIWNg"},"source":["- k 값이 작을 수록 모델의 복잡도가 상대적으로 증가.\n","    (noise 값에 민감)\n","- 반대로 k 값이 작아질수록 모델의 복잡도가 낮아진다.\n","- 100개의 데이터를 학습하고 k를 100개로 설정하여 예측하면 빈도가 가장 많은 클래스 레이블로 분류\n"]},{"cell_type":"markdown","metadata":{"id":"IDRb_B6DIaJJ"},"source":["앵그리버드는 팽귄? or 닭?\n","\n","<center>\n"," <img src=\"https://t1.daumcdn.net/cfile/tistory/110188344CEB80083A\" alt=\"앵그리버드 팽귄 닭\" width=\"60%\" />\n","\n","</center>"]},{"cell_type":"markdown","metadata":{"id":"eQy4IzkuIdXm"},"source":["유클리디안 거리 (Euclidean distance) : 두 점사이의 거리를 계산할 때 쓰이는 방법\n","- 두 점 (p1, p2, ...)와 (q1, q2, ....)의 거리\n","\n","\n","유클리디안 거리 공식\n","\n"," <img src=\"https://wikidocs.net/images/page/24654/2%EC%B0%A8%EC%9B%90_%ED%8F%89%EB%A9%B4.png\" alt=\"유클리디안 거리\" width=\"60%\" />\n","\n","</center>"]},{"cell_type":"markdown","metadata":{"id":"WPTQyM3aIhCf"},"source":["KNeighborsClassifier()\n","```\n","KNeighborsClassifier(n_neighbors, weights, algorithm, leaf_size, p, metric, metric_params, n_jobs)\n","```\n","- n_neighbors : 이웃의 수 (default : 5)\n","- weights : 예측에 사용된 가중 함수 (uniform, distance) (default : uniform)\n","- algorithm : 가까운 이웃을 계산하는데 사용되는 알고리즘 (auto, ball_tree, kd_tree, brute)\n","- leaf_size : BallTree 또는 KDTree에 전달 된 리프 크기\n","- p : (1 : minkowski_distance, 2: manhattan_distance 및 euclidean_distance)\n","- metric : 트리에 사용하는 거리 메트릭스\n","- metric_params : 메트릭 함수에 대한 추가 키워드 인수\n","- n_jobs : 이웃 검색을 위해 실행할 병렬 작업 수"]},{"cell_type":"markdown","metadata":{"id":"RBQSWlKfIkh5"},"source":["KNeighborsClassifier 모델은 k-최근접 이웃 분류 또는 KNN이라고 합니다. <br>\n","k-NN 알고리즘은 가장 가까운 훈련 데이터 포인트 K개를 최근접 이웃으로 찾아 예측에 사용합니다. <br>\n","n_neighbors=1 는 1개를 최근접 이웃으로 하겠다는 것입니다."]},{"cell_type":"markdown","metadata":{"id":"eWRzbL_EInlr"},"source":["주요 매개변수(Hyperparameter)\n","- 거리측정 방법, 이웃의 수, 가중치 함수 \n","\n","scikit-learn의 경우\n","- metric  :  유클리디언 거리 방식\n","- k : 이웃의 수\n","- weight  : 가중치 함수\n","     -  uniform : 가중치를 동등하게 설정.\n","     -  distance :  가중치를 거리에 반비례하도록 설정\n"]},{"cell_type":"markdown","metadata":{"id":"4c41rL5WIpqf"},"source":["장단점\n","- 이해하기 매우 쉬운 모델\n","- 훈련 데이터 세트가 크면(특성,샘플의 수) 예측이 느려진다\n","- 수백 개 이상의 많은 특성을 가진 데이터 세트와 특성 값 대부분이 0인 희소(sparse)한 데이터 세트에는 잘 동작하지 않는다\n","- 거리를 측정하기 때문에 같은 scale을 같도록 정규화 필요\n"]}]}