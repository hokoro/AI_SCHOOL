{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"cheon3_A_ solve_analogies.ipynb","provenance":[{"file_id":"1Ac7mNye_GJ9ZnlWBjCYYu2hSLGV4J6C5","timestamp":1629251527650}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"wzbsWQIoig6Z"},"source":["# 3_A_solve_analogies\n","- author: Eu-Bin KIM\n","- 17th of August 2021\n","\n","## 목표\n","1. 사전훈련된 Word2Vec 모델을 활용하여 비유문제를 푸는 함수, `solve_analogy()` 함수를 구현하는 것이 이번 숙제의 주된 목표입니다.\n","2. 재밌는 비유를 찾아보세요! (e.g. `밤:낮::달:X`)\n","3. 편향(bias) 문제에 대해서도 고민해볼 것입니다. (e.g. 사회에서 남자와 여자의 역할을 모델은 어떻게 판단할까?)\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rzu_Eq90qFCu","executionInfo":{"status":"ok","timestamp":1629351728700,"user_tz":-540,"elapsed":3352,"user":{"displayName":"천영성","photoUrl":"","userId":"06905110897473075189"}},"outputId":"1d707bfb-0751-4f49-916d-95c4d1838850"},"source":["# 이번에는 gensim 라이브러리를 사용해보겠습니다.\n","# https://radimrehurek.com/gensim/auto_examples/index.html\n","!pip3 install gensim  \n","from typing import List, Tuple\n","from gensim.models import KeyedVectors\n","import gensim.downloader as api\n","import numpy as np\n","\n","# 모델의 다운로드 현황을 확인하기 위해서 로깅 레벨을 수정합니다.\n","from sys import stdout\n","import logging\n","logging.basicConfig(stream=stdout, level=logging.INFO)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n","Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.19.5)\n","Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.4.1)\n","Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.1.0)\n","Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.15.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A6gc7U7Xp8rn","executionInfo":{"status":"ok","timestamp":1629351910390,"user_tz":-540,"elapsed":181703,"user":{"displayName":"천영성","photoUrl":"","userId":"06905110897473075189"}},"outputId":"52062e12-4d4e-4d20-ae7f-2fea0abe0175"},"source":["# --- 전역 상수 및 변수 설정 --- #\n","TOP_N = 20\n","# 차원의 크기 = 200으로 설정하여 학습을 진행한 Word2Vec (정확히는 Glove라는 모델)를 로드해보려고 합니다.\n","WORD2VEC_MODEL = \"glove-wiki-gigaword-200\"\n","# 사전훈련된 모델을 다운로드 (252.MB) 정도되는 모델.\n","# 모델의 가중치 (\"projection weights\")를 로드하는데 시간이 좀 걸릴 겁니다.\n","# 다운로드 가능한 다른 모델 리스트는 https://github.com/RaRe-Technologies/gensim-data#available-data\n","# 여기에서 확인해볼 수 있습니다.\n","wv: KeyedVectors = api.load(WORD2VEC_MODEL)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["INFO:gensim.api:Creating /root/gensim-data\n","[==================================================] 100.0% 252.1/252.1MB downloaded\n","INFO:gensim.api:glove-wiki-gigaword-200 downloaded\n","INFO:gensim.models.utils_any2vec:loading projection weights from /root/gensim-data/glove-wiki-gigaword-200/glove-wiki-gigaword-200.gz\n","INFO:gensim.models.utils_any2vec:loaded (400000, 200) matrix from /root/gensim-data/glove-wiki-gigaword-200/glove-wiki-gigaword-200.gz\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"X-1aZgoWquXT"},"source":["**Q: `KeyedVectors` 로는 무엇을 할 수 있나요?**\n","> A: 어휘에 존재하는 단어의 임베딩 벡터를 불러올 수 있고 [(`wv.get_vector()`](https://radimrehurek.com/gensim/models/keyedvectors.html#gensim.models.keyedvectors.KeyedVectors.get_vector), 주어진 단어 혹은 단어 벡터와 유사한 단어를 확인할 수 있는 [(`wv.similar_by_word()`](https://radimrehurek.com/gensim/models/keyedvectors.html#gensim.models.keyedvectors.KeyedVectors.similar_by_word) , [`wv.similar_by_vector()`](https://radimrehurek.com/gensim/models/keyedvectors.html#gensim.models.keyedvectors.KeyedVectors.similar_by_vector) 멤버 함수를 지원하는 객체입니다.\n","  \n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dPvfGdfxtgCf","executionInfo":{"status":"ok","timestamp":1629351910922,"user_tz":-540,"elapsed":539,"user":{"displayName":"천영성","photoUrl":"","userId":"06905110897473075189"}},"outputId":"c3b1a559-38a7-44cc-fb2e-8e6126bcab1c"},"source":["# --- wv 사용예시 --- # \n","# wv.get_vector(단어)를 사용하여, 어휘에 존재하는 특정 단어의 임베딩 벡터를 넘파이 배열로 불러올 수 있습니다.\n","car_vec: np.ndarray = wv.get_vector(\"car\")\n","# Word2Vec 모델은 예측 기반 모델이므로, 벡터가 희소하지 않으며 밀도가 높습니다. \n","print(car_vec)\n","# 벡터의 크기를 200으로 설정한 후 학습한 모델이니, 당연히 벡터의 차원은 200일 것입니다.\n","print(car_vec.shape)\n","# similar_by_word로 어휘에 존재하는 단어로 유사어를 구해볼 수 있습니다.\n","for word, score in wv.similar_by_word(\"car\", topn=TOP_N):\n","  print(word, score)\n","#print(\"-----\")\n","# similar_by_vector로는 임베딩 벡터로 유사어를 구해볼 수 있습니다.\n","for word, score in wv.similar_by_vector(car_vec, topn=TOP_N):\n","  print(word, score)\n","\n","# ----------------- #"],"execution_count":3,"outputs":[{"output_type":"stream","text":["[ 1.5682e-02  1.9355e-01 -5.5093e-01 -7.0453e-02 -6.5923e-01  2.5597e-01\n"," -3.4435e-01 -1.7964e-01  6.3907e-01 -4.1880e-01  3.1996e-01  3.3546e-01\n","  2.1122e-01  4.1592e-01  2.8599e-01 -2.5777e-01 -1.3341e-01 -2.5731e-01\n","  2.7712e-01 -3.2695e-01  1.1008e-01  2.7322e+00  4.6684e-01 -7.3542e-01\n","  1.1934e-01 -6.0756e-01  1.8882e-01  1.6739e-01  7.1712e-02 -6.5601e-01\n"," -5.1485e-01  7.6970e-01 -1.6761e-02 -1.9893e-01  2.7478e-01  1.5767e-01\n","  3.0154e-03 -3.5170e-01  1.3830e-01  6.0107e-01  1.9442e-01 -1.1802e-01\n"," -7.5983e-01  6.8567e-01  3.1139e-01  2.6280e-01  3.9558e-01 -6.9782e-01\n"," -2.1649e-01 -2.9196e-01  2.5405e-02  2.3887e-01  7.7817e-01 -4.7592e-02\n"," -2.3215e-01  6.1213e-02 -4.8265e-02 -2.0152e-01  3.2679e-01 -3.4759e-01\n","  9.9897e-02 -5.1759e-01 -5.9987e-01  1.3594e-01  9.4825e-03 -9.0824e-01\n"," -1.3166e-01 -3.7136e-01 -9.6381e-02 -4.3759e-01 -1.5774e-01  3.3517e-01\n","  1.3741e-01  8.2091e-02 -3.2295e-01  2.4789e-01 -7.3261e-03  2.5045e-03\n"," -1.0734e-01  3.8338e-01 -4.6347e-01 -1.7817e-01  2.8995e-01 -2.3342e-01\n","  3.5332e-01 -5.4913e-01 -7.1703e-01 -4.9411e-01 -1.0706e-01 -8.6577e-01\n","  9.7669e-02  8.9720e-01 -6.3157e-01  2.4803e-01 -1.3675e-01 -1.7690e-01\n"," -2.4218e-01 -6.2428e-01 -4.7577e-01 -1.4146e-01 -3.4351e-01  1.2621e-01\n"," -5.8372e-01  1.2055e-01 -4.1401e-02 -1.2253e-01  1.5960e-01  3.1284e-01\n","  4.8291e-01  3.7330e-02  3.7515e-01 -3.2352e-01 -4.5301e-01  2.1923e-01\n"," -1.4680e-01 -5.7464e-01  4.2237e-01 -5.7580e-01  4.8010e-01 -4.9366e-01\n","  8.3043e-01  1.0251e-01  1.4350e-01  4.4801e-01  4.2419e-01 -2.2976e-01\n","  2.2213e-01 -2.8515e-01  4.3249e-01 -7.3253e-01 -1.4583e-01 -7.0181e-02\n","  9.4005e-01 -1.2931e+00 -5.7515e-01  1.7507e-01 -8.7849e-02 -1.1623e-02\n","  1.9701e-01 -5.8473e-02 -4.2427e-01 -1.2315e-01  1.3216e-01 -5.3331e-02\n","  1.4086e+00  2.2520e-01  1.7757e-01 -3.5679e-01  6.7832e-01  5.4996e-01\n","  5.4456e-01 -3.3238e-01 -3.5155e-01 -4.8678e-02 -3.5712e-02  6.9322e-01\n","  3.1964e-01  1.6584e-01 -1.0904e+00 -8.1568e-01 -3.5108e-01 -2.5780e-01\n","  3.0240e-02  4.4872e-01 -2.0936e-01 -2.7535e-01  7.0283e-02 -4.5958e-01\n"," -4.6557e-01 -1.3999e-01  3.1803e-01 -8.6461e-01  1.2341e-01  4.5735e-01\n","  5.7170e-01 -2.2360e-03  3.4744e-01 -1.3559e-01 -2.0164e-01  3.0560e-01\n","  1.3520e+00 -6.0270e-01  2.7976e-01 -4.1820e-01  7.6646e-01 -3.1769e-01\n"," -3.0510e-01  7.6640e-01  4.8001e-01  2.6505e-01 -6.1196e-01  7.2399e-01\n"," -5.3557e-01  2.3302e-01  5.5782e-01  1.9308e-01 -5.9356e-02 -4.2328e-02\n"," -1.1459e+00  5.1091e-01]\n","(200,)\n","INFO:gensim.models.keyedvectors:precomputing L2-norms of word weight vectors\n","cars 0.8199902772903442\n","vehicle 0.8115566968917847\n","driver 0.7699719667434692\n","truck 0.7657698392868042\n","driving 0.7070207595825195\n","vehicles 0.6832183599472046\n","motorcycle 0.6503093242645264\n","parked 0.6456782817840576\n","drivers 0.6364123821258545\n","bus 0.6304870843887329\n","automobile 0.6265097856521606\n","mercedes 0.6147862672805786\n","auto 0.6129034757614136\n","suv 0.6102900505065918\n","taxi 0.6032224893569946\n","drove 0.5923401117324829\n","dealership 0.5890681743621826\n","motorbike 0.580419659614563\n","garage 0.5799648761749268\n","jeep 0.5753358602523804\n","car 1.0\n","cars 0.8199902772903442\n","vehicle 0.8115566968917847\n","driver 0.7699719667434692\n","truck 0.765769898891449\n","driving 0.7070207595825195\n","vehicles 0.6832183599472046\n","motorcycle 0.6503093242645264\n","parked 0.6456782817840576\n","drivers 0.6364123821258545\n","bus 0.6304870843887329\n","automobile 0.6265097856521606\n","mercedes 0.6147863268852234\n","auto 0.6129034757614136\n","suv 0.6102900505065918\n","taxi 0.6032224893569946\n","drove 0.5923401117324829\n","dealership 0.5890682339668274\n","motorbike 0.580419659614563\n","garage 0.5799648761749268\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"PJzys9WXAWGP"},"source":["**Q: 벡터의 연산으로 `A:B::C:X`를 만족하는 가장 적절한 X를 어떻게 구할 수 있을까요?**\n","\n","`A:B::C:X` 를 풀어서 생각을 해보면,\n","\n","`관계(A,B)` ~= `관계(C, X)`를 만족하는 가장 적절한 `X`를 찾는 과정이라고 생각해볼 수 있습니다.\n","\n","그럼 두 `관계`가 동일하다는 것은 어떻게 수학적으로 정의할 수 있을까요? \n","\n","만약 두 벡터 사이의 차(Difference)가 유사하다면, 같은 `관계`에 있다고 볼 수 있을 것입니다, 즉 위 식을 `A - B = C - X`로 나타낼 수 있습니다.\n","\n","\n","\n","관계 (king,man)\n","= king - man\n","\n","관계 (queen,woman)\n","= queen - woman\n","\n","\n","\n","\n","예를 들어,\n","- `king:man::queen:x`\n","-  = `관계(king,man) ~= 관계(queen,X)`\n","-  = `king - man ~= queen - x`\n","-  =  `x ~= queen - king + man`\n","-  =  `x` ~= woman, girl, etc\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"N0haiN4KjbF2","executionInfo":{"status":"ok","timestamp":1629351910922,"user_tz":-540,"elapsed":8,"user":{"displayName":"천영성","photoUrl":"","userId":"06905110897473075189"}}},"source":["def solve_analogy(a: str, b: str, c: str):\n","    \"\"\"\n","    :param wv: a pre-trained word2vec model\n","    :param a: word a\n","    :param b: word b\n","    :param c: word c\n","    \"\"\"\n","    global TOP_N, RESTRICT_VOCAB, wv\n","    # ---- TODO 1 -------\n","    # Write your implementation here.\n","    # get a continuous & distributed vector representation of a, b and c, using wv.\n","    # use vector arithmetics to get a vector representation of x, such that a is to b as in c is to x.\n","    a_vec = wv.get_vector(a)\n","    b_vec = wv.get_vector(b)\n","    c_vec = wv.get_vector(c)\n","    x = c_vec-a_vec+b_vec\n","    sims: List[Tuple[str, float]] = [(word,score) for word, score in wv.similar_by_word(x, topn=TOP_N)]\n","    # ------------------\n","    print(\"### {} : {} = {} : X ###\".format(a, b, c))\n","    for word, score in sims:\n","        print(word, score)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p_CX6CsyJx7h","executionInfo":{"status":"ok","timestamp":1629351976446,"user_tz":-540,"elapsed":348,"user":{"displayName":"천영성","photoUrl":"","userId":"06905110897473075189"}},"outputId":"2b650eab-e104-4f3d-b16c-64acaaf6bb36"},"source":["a = wv.get_vector('king')\n","b = wv.get_vector('man')\n","c = wv.get_vector('queen')\n","d = wv.get_vector('woman')\n","x = a-b\n","for word, score in wv.similar_by_word(x, topn=TOP_N):\n","  print(word, score)\n","print('-'*20)\n","x = c-d\n","for word, score in wv.similar_by_word(x, topn=TOP_N):\n","  print(word, score)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["king 0.6220163106918335\n","jeongjo 0.5617712736129761\n","seongjong 0.5423533916473389\n","vajiravudh 0.5373874306678772\n","seonjo 0.5194161534309387\n","taejong 0.5177606344223022\n","injo 0.514464259147644\n","bagyidaw 0.5124008655548096\n","kalākaua 0.5123972296714783\n","alveda 0.5079326033592224\n","jangsu 0.5077317953109741\n","dutugemunu 0.5030213594436646\n","yeongjo 0.49635183811187744\n","prajadhipok 0.49147698283195496\n","gojong 0.4895187020301819\n","goujian 0.48051905632019043\n","elessar 0.47993889451026917\n","sigismund 0.47762852907180786\n","childeric 0.4771452248096466\n","andrianampoinimerina 0.47641539573669434\n","--------------------\n","queen 0.5596188306808472\n","seondeok 0.4919939339160919\n","ranavalona 0.4457913637161255\n","monineath 0.4434443712234497\n","aiswarya 0.44089972972869873\n","liliuokalani 0.4362812638282776\n","ethelburga 0.4357687532901764\n","trux 0.4262790381908417\n","gorgo 0.4210543632507324\n","coronation 0.41778361797332764\n","tiye 0.41703301668167114\n","majesty 0.40700244903564453\n","twosret 0.40392279624938965\n","jubilee 0.40341731905937195\n","theodelinda 0.4033454656600952\n","savang 0.3993164896965027\n","liliʻuokalani 0.3982848525047302\n","salote 0.3954038619995117\n","veranke 0.3952362835407257\n","taramis 0.3937177062034607\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FBSMDZNiMBFr","executionInfo":{"status":"ok","timestamp":1629351910923,"user_tz":-540,"elapsed":6,"user":{"displayName":"천영성","photoUrl":"","userId":"06905110897473075189"}},"outputId":"fc76c104-0dd9-45dd-cd0f-d65d3d0e940e"},"source":["for word, score in wv.similar_by_word(a, topn=TOP_N):\n","  print(word, score)\n","\n","print(\"----------------------------------------------\")\n","for word, score in wv.similar_by_word(b, topn=TOP_N):\n","  print(word, score)\n","print(\"----------------------------------------------\")\n","for word, score in wv.similar_by_word(c, topn=TOP_N):\n","  print(word, score)\n","print(\"----------------------------------------------\")"],"execution_count":6,"outputs":[{"output_type":"stream","text":["king 1.0\n","prince 0.6854566931724548\n","queen 0.6665197610855103\n","kingdom 0.6303210258483887\n","monarch 0.6224350929260254\n","ii 0.6146443486213684\n","throne 0.6074705123901367\n","reign 0.5911680459976196\n","iii 0.5837125778198242\n","crown 0.579647958278656\n","emperor 0.5552704334259033\n","uncle 0.5516200065612793\n","brother 0.550816535949707\n","iv 0.5469068288803101\n","kings 0.5457847714424133\n","son 0.5428785085678101\n","henry 0.5391765832901001\n","ruler 0.5303810834884644\n","edward 0.5291287899017334\n","royal 0.5288981795310974\n","----------------------------------------------\n","man 1.0\n","woman 0.7520086765289307\n","person 0.6917078495025635\n","another 0.6866575479507446\n","boy 0.6848181486129761\n","one 0.6820704340934753\n","who 0.6693941950798035\n","he 0.6683939695358276\n","himself 0.6633234620094299\n","him 0.6628837585449219\n","his 0.6352562308311462\n","young 0.6347833871841431\n","life 0.6307883858680725\n","old 0.6296941041946411\n","father 0.6261577010154724\n","men 0.6218826770782471\n","when 0.6199896931648254\n","once 0.6141794919967651\n","dead 0.6095000505447388\n","turned 0.6071626543998718\n","----------------------------------------------\n","queen 1.0\n","elizabeth 0.6924378871917725\n","king 0.6665197610855103\n","princess 0.662910521030426\n","monarch 0.6128137707710266\n","victoria 0.6093795299530029\n","royal 0.6071122288703918\n","crown 0.5574186444282532\n","majesty 0.5540481805801392\n","throne 0.552193284034729\n","lady 0.5454801321029663\n","coronation 0.5426240563392639\n","mary 0.5376039147377014\n","margaret 0.5298653841018677\n","prince 0.5245172381401062\n","anne 0.5238583087921143\n","consort 0.51944899559021\n","beatrix 0.5102985501289368\n","duchess 0.5050047636032104\n","sister 0.5039376020431519\n","----------------------------------------------\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ho6iiOCpp3rs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629351911428,"user_tz":-540,"elapsed":509,"user":{"displayName":"천영성","photoUrl":"","userId":"06905110897473075189"}},"outputId":"abebce1f-e762-4ca7-f6ff-0d0d2626e5d9"},"source":["# 한번 비유문제를 풀어봅시다!\n","solve_analogy(\"king\", \"man\", \"queen\")  # 왕:남자::여왕:X\n","solve_analogy(\"have\", \"had\", \"get\")  # have:had::get:X\n","solve_analogy(\"korea\", \"seoul\", \"england\")  # 한국:서울::영국:X\n","solve_analogy(\"night\", \"noon\", \"moon\")  # 밤:낮::달:X\n","solve_analogy(\"korea\", \"kimchi\", \"england\")  # 한국:김치::영국:X?\n","solve_analogy(\"us\", \"trump\", \"korea\")  # 미국:트럼프::한국:X?"],"execution_count":7,"outputs":[{"output_type":"stream","text":["### king : man = queen : X ###\n","woman 0.7018729448318481\n","man 0.6981476545333862\n","girl 0.5718171000480652\n","she 0.5551059246063232\n","her 0.546249508857727\n","mother 0.5334489345550537\n","queen 0.5116901397705078\n","beautiful 0.509249210357666\n","teenager 0.5078386664390564\n","person 0.5015807151794434\n","boy 0.49607059359550476\n","herself 0.4940054416656494\n","wife 0.4905710220336914\n","men 0.49014854431152344\n","blonde 0.48988908529281616\n","young 0.48825371265411377\n","lady 0.4844915270805359\n","one 0.4833947420120239\n","blond 0.4832534193992615\n","life 0.48230481147766113\n","### have : had = get : X ###\n","got 0.8583781123161316\n","get 0.8212234973907471\n","getting 0.7435371279716492\n","had 0.7194944024085999\n","him 0.713526725769043\n","'d 0.7016146183013916\n","when 0.7001579999923706\n","just 0.6940717101097107\n","out 0.6917241811752319\n","then 0.6907411813735962\n","me 0.6866481304168701\n","put 0.6853894591331482\n","up 0.682799220085144\n","wanted 0.6817044019699097\n","did 0.6783760786056519\n","never 0.6740534901618958\n","gets 0.6721766591072083\n","knew 0.6705450415611267\n","i 0.6687175035476685\n","gave 0.6681201457977295\n","### korea : seoul = england : X ###\n","england 0.7255815267562866\n","london 0.6356680989265442\n","birmingham 0.589836835861206\n","surrey 0.5772858262062073\n","manchester 0.5481588840484619\n","oxford 0.529553234577179\n","melbourne 0.5265653133392334\n","liverpool 0.5259275436401367\n","nottingham 0.5229343175888062\n","perth 0.5212391018867493\n","middlesex 0.5197691917419434\n","essex 0.5164851546287537\n","sydney 0.5065154433250427\n","wales 0.4976809024810791\n","leeds 0.49399301409721375\n","lancashire 0.48844075202941895\n","newcastle 0.4875320792198181\n","leicester 0.48324066400527954\n","dublin 0.48185762763023376\n","warwickshire 0.4804612398147583\n","### night : noon = moon : X ###\n","moon 0.7155050039291382\n","noon 0.539372444152832\n","lunar 0.4896060824394226\n","enceladus 0.46816378831863403\n","ki 0.45321711897850037\n","mullican 0.4399142861366272\n","gibbous 0.4230325222015381\n","mid-autumn 0.4199249744415283\n","earth 0.41744324564933777\n","sun 0.41505134105682373\n","gmt 0.41371652483940125\n","orbit 0.41151708364486694\n","mars 0.4062110185623169\n","jamario 0.4036266803741455\n","2150 0.4003942608833313\n","chibi 0.3914622664451599\n","pournami 0.3913351893424988\n","mimas 0.39115777611732483\n","midnight 0.39095601439476013\n","sunrise 0.3900896906852722\n","### korea : kimchi = england : X ###\n","surrey 0.4262450635433197\n","warwickshire 0.42526546120643616\n","sussex 0.4186975955963135\n","england 0.41754770278930664\n","lancashire 0.4137398898601532\n","alastair 0.41208115220069885\n","atherton 0.4097963273525238\n","worcestershire 0.4054810702800751\n","chowder 0.3995121419429779\n","botham 0.3986336588859558\n","gloucestershire 0.39783424139022827\n","tipton 0.38946184515953064\n","bopara 0.3883880376815796\n","trescothick 0.3866896629333496\n","staines 0.3828696012496948\n","chertsey 0.3802623748779297\n","essex 0.37837255001068115\n","middlesex 0.3772238790988922\n","halesowen 0.37714576721191406\n","gully 0.37583282589912415\n","### us : trump = korea : X ###\n","trump 0.5992231369018555\n","korea 0.5070021152496338\n","pyongyang 0.41019734740257263\n","incheon 0.3933596611022949\n","kathie 0.3807404041290283\n","knauss 0.3795280456542969\n","kang 0.36351221799850464\n","ivanka 0.361664354801178\n","koreas 0.36132609844207764\n","dprk 0.3603391647338867\n","seoul 0.35804152488708496\n","seogwipo 0.3574312627315521\n","ivana 0.3561338484287262\n","kdb 0.3520340025424957\n","wook 0.3519665002822876\n","trinkle 0.34896302223205566\n","jong 0.3433922529220581\n","jeju 0.34168463945388794\n","choi 0.3405158519744873\n","eun 0.3400920033454895\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"EDsdKrdHw5Ox"},"source":["다음과 같은 결과가 나와야 합니다:\n","```\n","### king : man = queen : X ###\n","woman 0.7018729448318481\n","man 0.6981476545333862\n","girl 0.5718171000480652\n","she 0.5551059246063232\n","her 0.546249508857727\n","mother 0.5334489345550537\n","queen 0.5116901397705078\n","beautiful 0.509249210357666\n","teenager 0.5078386664390564\n","person 0.5015807151794434\n","### have : had = get : X ###\n","got 0.8583781123161316\n","get 0.8212234973907471\n","getting 0.7435371279716492\n","had 0.7194944024085999\n","him 0.713526725769043\n","'d 0.7016146183013916\n","when 0.7001579999923706\n","just 0.6940717101097107\n","out 0.6917241811752319\n","then 0.6907411813735962\n","### korea : seoul = england : X ###\n","england 0.7255815267562866\n","london 0.6356680989265442\n","birmingham 0.589836835861206\n","surrey 0.5772858262062073\n","manchester 0.5481588840484619\n","oxford 0.529553234577179\n","melbourne 0.5265653133392334\n","liverpool 0.5259275436401367\n","nottingham 0.5229343175888062\n","perth 0.5212391018867493\n","### night : noon = moon : X ###\n","moon 0.7155050039291382\n","noon 0.539372444152832\n","lunar 0.4896060824394226\n","enceladus 0.46816378831863403\n","ki 0.45321711897850037\n","mullican 0.4399142861366272\n","gibbous 0.4230325222015381\n","mid-autumn 0.4199249744415283\n","earth 0.41744324564933777\n","sun 0.41505134105682373\n","### korea : kimchi = england : X ###\n","surrey 0.4262450635433197\n","warwickshire 0.42526546120643616\n","sussex 0.4186975955963135\n","england 0.41754770278930664\n","lancashire 0.4137398898601532\n","alastair 0.41208115220069885\n","atherton 0.4097963273525238\n","worcestershire 0.4054810702800751\n","chowder 0.3995121419429779\n","botham 0.3986336588859558\n","### us : trump = korea : X ###\n","trump 0.5992231369018555\n","korea 0.5070021152496338\n","pyongyang 0.41019734740257263\n","incheon 0.3933596611022949\n","kathie 0.3807404041290283\n","knauss 0.3795280456542969\n","kang 0.36351221799850464\n","ivanka 0.361664354801178\n","koreas 0.36132609844207764\n","dprk 0.3603391647338867\n","```"]},{"cell_type":"code","metadata":{"id":"hI4_ncNMIN82","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629352283403,"user_tz":-540,"elapsed":354,"user":{"displayName":"천영성","photoUrl":"","userId":"06905110897473075189"}},"outputId":"d5cc5a23-9d42-42ab-8522-7f75480b012f"},"source":["# --- TODO 2 --- # \n","# 더 재밌는 비유의 예시를 찾아보세요!\n","\n","# -------------- #\n","solve_analogy(\"computer\",\"cpu\",\"human\")"],"execution_count":12,"outputs":[{"output_type":"stream","text":["### computer : cpu = human : X ###\n","cpu 0.5760547518730164\n","human 0.549921452999115\n","cpus 0.4083137512207031\n","habitations 0.3941327631473541\n","fertilisation 0.3885045051574707\n","hrc 0.384643018245697\n","organs 0.3812401592731476\n","non-human 0.3812362849712372\n","microbiome 0.38003236055374146\n","sinfulness 0.36876028776168823\n","navi 0.36555713415145874\n","dual-core 0.3652608394622803\n","pchr 0.3643554449081421\n","digestion 0.3637053072452545\n","ldh 0.3594871163368225\n","pillay 0.3591841459274292\n","rights 0.3577858805656433\n","dignity 0.3576926290988922\n","68000 0.35552144050598145\n","finitude 0.35413581132888794\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"-1DfFFYrJDBe"},"source":["앞선 수업에서, Distributional Semantics 가정을 기반으로 데이터로부터 임베딩 벡터를 얻는 방법은, 편향(bias)을 고려하지 않는 실수를 범하기 쉽다고 했었습니다. 편향관리를 실패한 대표적인 예시로 [이루다 서비스](https://media.scatterlab.co.kr/1-11-media)를 예시로 들기도 했었구요. \n","\n","비단 우리가 지금 사용하고 있는 Word2Vec 모델도 편향된 부분이 있을 것입니다. 우리가 구현한 `solve_analogy()` 함수를 활용해 학습한 편향을 찾아보도록 하겠습니다. \n","\n","## TODO 3\n","> 밑의 코드를 실행하고, 결과를 비교해보세요. 어떤 문제를 발견할 수 있나요?\n"]},{"cell_type":"code","metadata":{"id":"noBPgc2iJY5V","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629351911791,"user_tz":-540,"elapsed":364,"user":{"displayName":"천영성","photoUrl":"","userId":"06905110897473075189"}},"outputId":"5acb0317-6f0e-446d-d0ae-7f7d80430b08"},"source":["# 남자의 역할이 노동자라면, 여자의 역할은 무엇인가?\n","solve_analogy(\"man\", \"worker\", \"woman\")  \n","# 여자의 역할이 노동자라면, 남자의 역할은 무엇인가?\n","solve_analogy(\"woman\", \"worker\", \"man\") "],"execution_count":9,"outputs":[{"output_type":"stream","text":["### man : worker = woman : X ###\n","worker 0.8469680547714233\n","woman 0.6489056348800659\n","employee 0.6411648988723755\n","workers 0.6075609922409058\n","nurse 0.5941476821899414\n","mother 0.5538603067398071\n","pregnant 0.5518734455108643\n","child 0.5260860919952393\n","teacher 0.5216445922851562\n","employer 0.5152565240859985\n","female 0.5103510022163391\n","homemaker 0.5048410892486572\n","waitress 0.5033119916915894\n","nurses 0.49936389923095703\n","elderly 0.49910637736320496\n","wife 0.4987758696079254\n","housewife 0.4957857131958008\n","maid 0.4885651469230652\n","employees 0.4863051772117615\n","schoolteacher 0.4851081371307373\n","### woman : worker = man : X ###\n","worker 0.7736103534698486\n","workers 0.6012227535247803\n","employee 0.5834685564041138\n","man 0.5822302103042603\n","working 0.5432349443435669\n","laborer 0.537001371383667\n","unemployed 0.5245610475540161\n","job 0.5122866034507751\n","work 0.5073323249816895\n","mechanic 0.5002841949462891\n","worked 0.4903597831726074\n","factory 0.48811790347099304\n","wages 0.4727928340435028\n","labor 0.4683865010738373\n","laborers 0.46706122159957886\n","contractor 0.45823678374290466\n","engineer 0.45811891555786133\n","jobs 0.45099297165870667\n","construction 0.4493839740753174\n","wage 0.4467262923717499\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"B5LIEps3_P-i"},"source":["고정관념에 빠진 편향이 발생한다.\n","= 이게 과연 모델의 잘못인가?\n"," /데이터에 대한 잘못인가?\n","\n"," AI Fairness \n","편향 되어있지 않은 데이터로 중립적인 모델을 지킬수 있는가 "]}]}