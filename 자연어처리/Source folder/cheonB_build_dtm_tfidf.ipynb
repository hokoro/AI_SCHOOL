{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"cheonB_build_dtm_tfidf.ipynb","provenance":[{"file_id":"1rd-XvVE-GeJNh1ZJYDocLk-fpZEx2Vgo","timestamp":1628034974386}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8iUsnxOyHhD4","executionInfo":{"status":"ok","timestamp":1628141574567,"user_tz":-540,"elapsed":7896,"user":{"displayName":"천영성","photoUrl":"","userId":"06905110897473075189"}},"outputId":"0961d70b-1f7f-4cc2-d745-d8965288b378"},"source":["# install & import the libraries needed\n","!pip3 install pandas\n","!pip3 install scikit-learn\n","from typing import List\n","from math import log\n","import numpy as np\n","import pandas as pd\n","import random\n","from sklearn.metrics.pairwise import cosine_similarity\n","# for printing out all the columns of a pandas dataframe https://towardsdatascience.com/how-to-show-all-columns-rows-of-a-pandas-dataframe-c49d4507fcf\n","pd.set_option('display.max_columns', None)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.1.5)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.1)\n","Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.19.5)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (0.22.2.post1)\n","Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.4.1)\n","Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.19.5)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.0.1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Pg4U3QY2IB_v"},"source":["# The corpus\n","CORPUS = [\n","    'this is the first document',\n","    'the first document is this',\n","    'this is the second document',\n","    'and this is the third document',\n","    'is this the first document'\n","]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zQ2uAyiBIGbD"},"source":["# we will reuse the functions we completed in the previous tutorial\n","def tf(term: str, doc: str) -> int:\n","        tf = sum([word == term for word in doc.split(\" \")])  # word count\n","        return tf\n","\n","\n","def build_dtm(corpus: List[str]) -> pd.DataFrame:\n","    \"\"\"\n","    we reuse what we implemented in previous tutorial\n","    :param corpus:\n","    :return:\n","    \"\"\"\n","    # build vocabulary - use nested list comprehension, set, and list\n","    words = [\n","        word\n","        for doc in corpus\n","        for word in doc.split(\" \")\n","    ]\n","    vocab = list(set(words))\n","\n","    # populate dtm, ith a nested for loop\n","    dtm = []\n","    for doc in corpus:\n","        row = list()\n","        for term in vocab:\n","            term_freq = tf(term, doc)\n","            row.append(term_freq)\n","        dtm.append(row)\n","\n","    # return dtm as a pandas dataframe\n","    dtm = pd.DataFrame(data=dtm, columns=vocab)\n","    return dtm\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5888fENLIQqX"},"source":["# complete this function\n","def idf(term: str, corpus: List[str]) -> float:\n","    ### TODO 1 ###\n","    #idf = np.log(len(CORPUS)/(1+term))\n","    \n","    n = len(corpus)\n","    df = sum([\n","      term in doc.split(\" \") #boolean 값이 나온다\n","      for doc corpus \n","    ])\n","\n","    idf  = log(n/(1+df))\n","    \n","    return idf"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sZ4-x2kMJsnl"},"source":["def build_dtm_with_tfidf(corpus: List[str]) -> pd.DataFrame:\n","    # access the columns with df.columns\n","    # multiply idfs to each row with numpy's broadcast mul\n","    dtm = build_dtm(corpus) #tf\n","    term = list(dtm.columns)\n","    dtm_np = dtm.to_numpy()\n","    dtm_sum = np.sum(dtm_np,axis =0) \n","    \n","    ### TODO 2 ####\n","    # reuse dtm to build dtm_tfidf\n","    # use dtm.columns, idf, np.array(), dtm.to_numpy() and broadcast multiplication\n","    idfs: List[float] = np.array([[idf(term,doc) for term in dtm_sum] for doc in corpus])\n","    '''\n","    idfs: List[float] = [idf(term,corpus) for term in dtm.columns]\n","    '''\n","    dtm_tfidf: List[List[float]] = dtm.to_numpy() * idfs\n","\n","    '''\n","     dtm_tfidf: List[List[float]] = dtm.to_numpy() * idfs.to_numpy()\n","    '''\n","    \n","    \n","    \n","    #print(idfs)\n","    ############### \n","    return pd.DataFrame(data=dtm_tfidf, columns=dtm.columns)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":312},"id":"rB_5uAIrKPqf","executionInfo":{"status":"ok","timestamp":1628141574570,"user_tz":-540,"elapsed":16,"user":{"displayName":"천영성","photoUrl":"","userId":"06905110897473075189"}},"outputId":"72bfa917-8f7f-4462-f991-45a5510cef78"},"source":["# build dtm, and one with  \n","dtm = build_dtm(CORPUS)\n","dtm_tfidf = build_dtm_with_tfidf(CORPUS)\n","print(dtm)\n","display(dtm_tfidf)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["   this  is  third  second  first  the  document  and\n","0     1   1      0       0      1    1         1    0\n","1     1   1      0       0      1    1         1    0\n","2     1   1      0       1      0    1         1    0\n","3     1   1      1       0      0    1         1    1\n","4     1   1      0       0      1    1         1    0\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>this</th>\n","      <th>is</th>\n","      <th>third</th>\n","      <th>second</th>\n","      <th>first</th>\n","      <th>the</th>\n","      <th>document</th>\n","      <th>and</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-0.182322</td>\n","      <td>-0.182322</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.223144</td>\n","      <td>-0.182322</td>\n","      <td>-0.182322</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-0.182322</td>\n","      <td>-0.182322</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.223144</td>\n","      <td>-0.182322</td>\n","      <td>-0.182322</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-0.182322</td>\n","      <td>-0.182322</td>\n","      <td>0.000000</td>\n","      <td>0.916291</td>\n","      <td>0.000000</td>\n","      <td>-0.182322</td>\n","      <td>-0.182322</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>-0.182322</td>\n","      <td>-0.182322</td>\n","      <td>0.916291</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>-0.182322</td>\n","      <td>-0.182322</td>\n","      <td>0.916291</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>-0.182322</td>\n","      <td>-0.182322</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.223144</td>\n","      <td>-0.182322</td>\n","      <td>-0.182322</td>\n","      <td>0.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       this        is     third    second     first       the  document  \\\n","0 -0.182322 -0.182322  0.000000  0.000000  0.223144 -0.182322 -0.182322   \n","1 -0.182322 -0.182322  0.000000  0.000000  0.223144 -0.182322 -0.182322   \n","2 -0.182322 -0.182322  0.000000  0.916291  0.000000 -0.182322 -0.182322   \n","3 -0.182322 -0.182322  0.916291  0.000000  0.000000 -0.182322 -0.182322   \n","4 -0.182322 -0.182322  0.000000  0.000000  0.223144 -0.182322 -0.182322   \n","\n","        and  \n","0  0.000000  \n","1  0.000000  \n","2  0.000000  \n","3  0.916291  \n","4  0.000000  "]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"4oAQVQquMV2G"},"source":["다음과 같은 결과가 나와야 합니다 (단어의 순서는 달라도 괜찮습니다):\n","```\n","   this  is  third  second  first  the  document  and\n","0     1   1      0       0      1    1         1    0\n","1     1   1      0       0      1    1         1    0\n","2     1   1      0       1      0    1         1    0\n","3     1   1      1       0      0    1         1    1\n","4     1   1      0       0      1    1         1    0\n","\n","      this\t     is\t    third\t   second\t   first\t  the\tdocument\tand     \n","0\t-0.182322\t-0.182322\t0.000000\t0.000000\t0.223144\t-0.182322\t-0.182322\t0.000000\n","1\t-0.182322\t-0.182322\t0.000000\t0.000000\t0.223144\t-0.182322\t-0.182322\t0.000000\n","2\t-0.182322\t-0.182322\t0.000000\t0.916291\t0.000000\t-0.182322\t-0.182322\t0.000000\n","3\t-0.182322\t-0.182322\t0.916291\t0.000000\t0.000000\t-0.182322\t-0.182322\t0.916291\n","4\t-0.182322\t-0.182322\t0.000000\t0.000000\t0.223144\t-0.182322\t-0.182322\t0.000000\n","\n","```"]},{"cell_type":"markdown","metadata":{"id":"YSEEqll0Kp--"},"source":[""]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2SsHSXRkKTLK","executionInfo":{"status":"ok","timestamp":1628141574570,"user_tz":-540,"elapsed":13,"user":{"displayName":"천영성","photoUrl":"","userId":"06905110897473075189"}},"outputId":"2669ed23-8427-4339-be53-2bd281896e63"},"source":["# compare the two\n","print(cosine_similarity(dtm.to_numpy(), dtm.to_numpy()))\n","print(cosine_similarity(dtm_tfidf.to_numpy(), dtm_tfidf.to_numpy()))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[[1.         1.         0.8        0.73029674 1.        ]\n"," [1.         1.         0.8        0.73029674 1.        ]\n"," [0.8        0.8        1.         0.73029674 0.8       ]\n"," [0.73029674 0.73029674 0.73029674 1.         0.73029674]\n"," [1.         1.         0.8        0.73029674 1.        ]]\n","[[1.         1.         0.31538537 0.23104796 1.        ]\n"," [1.         1.         0.31538537 0.23104796 1.        ]\n"," [0.31538537 0.31538537 1.         0.10015744 0.31538537]\n"," [0.23104796 0.23104796 0.10015744 1.         0.23104796]\n"," [1.         1.         0.31538537 0.23104796 1.        ]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"OzdJrp3mMfPg"},"source":["다음과 같은 결과가 나와야 합니다:\n","```\n","[[1.         1.         0.8        0.73029674 1.        ]\n"," [1.         1.         0.8        0.73029674 1.        ]\n"," [0.8        0.8        1.         0.73029674 0.8       ]\n"," [0.73029674 0.73029674 0.73029674 1.         0.73029674]\n"," [1.         1.         0.8        0.73029674 1.        ]]\n","\n","[[1.         1.         0.31538537 0.23104796 1.        ]\n"," [1.         1.         0.31538537 0.23104796 1.        ]\n"," [0.31538537 0.31538537 1.         0.10015744 0.31538537]\n"," [0.23104796 0.23104796 0.10015744 1.         0.23104796]\n"," [1.         1.         0.31538537 0.23104796 1.        ]]\n","```"]},{"cell_type":"markdown","metadata":{"id":"eg2616UaMrg6"},"source":["## 다음의 질문에 답해주세요!\n","\n","> `dtm`으로 구한 유사도 행렬 대비, `dtm_tfidf`로 구한 유사도 행렬은 어떤 점이 개선되었나요? 그 이유는?\n","\n","> `dtm_tfidf`로도 해결할수 없는 문제를 발견할 수 있나요?"]},{"cell_type":"code","metadata":{"id":"ZEGqECWqKo50"},"source":["#유사도를 측정하면서 다른 문장을 구분 할수 있다 \n","\n","#단어의 순서를 구분할수 없다 "],"execution_count":null,"outputs":[]}]}