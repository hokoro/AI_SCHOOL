{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"cheon2_A_cluster_words.ipynb","provenance":[{"file_id":"1c2r33GYHCkyjyEPb_iRCTLaCoMrsxfMG","timestamp":1628515413771}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"rIKsUuNbRQt7"},"source":["# Week 2-A 실습: Clustering Words with Co-occurence matrix\n","- author: Eu-Bin KIM\n","- @likelion\n","- tlrndk123@gmail.com\n","- 9th of August 2021\n","\n","## Overview\n","### `eval_clusters` 는 뭘하는 함수?\n","이 실습은 `target_words` 와 `target_words_reversed` 를 클러스터링 하는 것에 목표를 둡니다.\n","예를 들어,\n","```python3\n","target_words = [\"abstraction\", \"actually\", \"add\"]\n","target_words_reversed = [\"noitcartsba\", \"yllautca\", \"dda\"]\n","```\n","이라고 한다면, 먼저 이 단어들의 벡터 표현을 말뭉치로부터 co-occurence matrix 를 구축하여  얻습니다. 이 6개의 벡터포현을 클러스터링을 했을 때, 반전된 단어가 반전되기전 단어와 같은 클러스터에 존재하면 co-occurence matrix의 퀄리티가 좋다고 볼 수 있습니다:\n","```\n","# comat의 성능이 매우 좋음: accuracy = 3 / 3 = 1\n","[[\"abstraction\",\"noitcartsba\"],  \n"," [\"actually\", \"yllautca\"],\n"," [\"add\", \"dda\"]]\n","\n","# comat의 성능이 매우 안 좋음 accuracy = 0 / 3 = 0\n","[[\"abstraction\",\"yllautca\"],  \n"," [\"actually\", \"noitcartsba\", \"dda\"],\n"," [\"add\"]]\n","```\n","그렇게 pseudo-evaluation을 진행하면, 현재 구한 co-occurence matrix의 퀄리티를 정량적으로\n","측정할 수 있게됩니다(`accuracy`로 측정). 이를 측정하는 함수가 `eval_clusters` 함수입니다.  \n","\n","### `reverse_half` 는 뭘하는 함수?\n","\n","이런식의 평가를 진행하기 위해선, 반전된 단어의 벡터표현을 얻어야 합니다. 하지만 말뭉치에는\n","반전된 단어가 존재하지 않습니다. 때문에 말뭉치에 존재하는 `target_words`의 절반을 반전하는 작업이 필요합니다. 이를 위한 함수가 `reverse_half`입니다.\n","\n","예를들어,\n","```python3\n","CORPUS = \"actually, I actually like the way you actually speak. you actually seem to be a nice person.\"\n","```\n","이런 작은 말뭉치가 있다면, `CORPUS`에서 나타나는 `actually`의 절반을 뒤집어서 `yllautca`로 바꿔줍니다:\n","```python3\n","CORPUS = \"actually, I yllautca like the way you actually speak. you yllautca seem to be a nice person.\"\n","```\n","\n","이 전처리된 말뭉치를 바탕으로 co-occurence matrix를 구축하면, 이제, `actually`와 `yllautca`의 벡터표현을 모두 얻을 수 있게됩니다. 퀄리티가 좋은 co-occurence matrix라면 두 벡터는 매우 유사할 것입니다 (e.g. 모두 `like`, `speak`같은 동사와 같이 출현함). \n","\n","\n","### `build_count_comat`은 무엇을 하는 함수?\n","\n","그렇다면 위에서 언급한 co-occurence matrix란 무엇일까요? 우리가 알고 있는 Document-Term Matrix와 크게 다른 점은 없고, 단지 Document 와 Term 모두 말뭉치에서 추출한 어휘로 설정하게 되면, co-occurence matrix라고 부릅니다. \n","\n","예를들어, 다음과 같은 문장이 있다고 생각해보겠습니다:\n","> Roses are red. bees are yellow.\n","\n","만약 window가 2라면, 이 문장을 바탕으로 다음과 같은 bigrams를 만들어줄 수 있습니다.:\n","```\n","windows = [(Roses, are), (are, red), (red, bees), (bees, are), (are, yellow)]\n","```\n","\n","그럼 각 window를 살펴보며 다음과 같은 co-occurence matrix를 구축할 수 있습니다:\n","```\n","      |  Roses | are | red | bees | yellow\n","Roses |    1   |  1  |  0  |  0   |    0\n","are   |    1   |  1  |  1  |  1   |    1\n","red   |    1   |  1  |  1  |  1   |    0\n","bees  |    0   |  1  |  1  |  1   |    1\n","yellow|    0   |  0  |  0  |  0   |    1\n","```\n","\n","Roses와 are이 \"co-occur\"하는 window는 하나 뿐이기에 `comat[0, 1]` 에 해당하는 값은 1이 됩니다. are은 존재하는 모든 어휘와 co-occur하는 단어 이기에, `comat[1, :]`은 전부 1이 됩니다.\n","이렇게 주어진 `windows`를 바탕으로 `comat`을 구축하는 함수가 `build_count_comat`함수 입니다.\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BY60NBqUHP_N","executionInfo":{"status":"ok","timestamp":1628642501029,"user_tz":-540,"elapsed":5971,"user":{"displayName":"천영성","photoUrl":"","userId":"06905110897473075189"}},"outputId":"de71b14c-5e8c-4227-f0dc-dacfe2afb56c"},"source":["!pip3 install nltk\n","!pip3 install scikit-learn\n","from typing import List, Optional, Tuple\n","import nltk\n","from nltk.corpus import brown, product_reviews_2, stopwords\n","from nltk.stem import PorterStemmer\n","from nltk.stem import WordNetLemmatizer\n","from nltk.util import ngrams\n","import random\n","import numpy as np\n","from sklearn.cluster import KMeans\n","from tqdm import tqdm\n","from pprint import PrettyPrinter\n","\n","# --- constants --- #\n","# the target words to perform clustering on (total of 50 words)\n","TARGET_WORDS: str = \\\n","\"\"\"abstraction\n","actually\n","add\n","address\n","answer\n","argument\n","arguments\n","back\n","call\n","car\n","case\n","cdr\n","computer\n","course\n","dictionary\n","different\n","evaluator\n","function\n","general\n","got\n","idea\n","kind\n","lambda\n","machine\n","mean\n","object\n","operator\n","order\n","pair\n","part\n","particular\n","pattern\n","place\n","problem\n","process\n","product\n","program\n","reason\n","register\n","result\n","set\n","simple\n","structure\n","system\n","they\n","together\n","using\n","variable\n","why\n","zero\"\"\"\n","\n","BROWN_NAME = \"brown\"\n","PR2_NAME = \"product_reviews_2\"\n","RAND_STATE = 318  # to be used for k-means clustering\n","random.seed(RAND_STATE)\n","\n","stemmer = PorterStemmer()\n","lemmatiser = WordNetLemmatizer()\n","\n","nltk.download('wordnet')  # for lemmatisation.\n","nltk.download('stopwords') # for stopwords filtering\n","nltk.download(BROWN_NAME)\n","nltk.download(PR2_NAME)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (0.22.2.post1)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.0.1)\n","Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.19.5)\n","Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.4.1)\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package brown to /root/nltk_data...\n","[nltk_data]   Package brown is already up-to-date!\n","[nltk_data] Downloading package product_reviews_2 to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Package product_reviews_2 is already up-to-date!\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LyPE2r0IAMh4","executionInfo":{"status":"ok","timestamp":1628642506361,"user_tz":-540,"elapsed":5345,"user":{"displayName":"천영성","photoUrl":"","userId":"06905110897473075189"}},"outputId":"38091e39-424c-4d91-ba97-35d51011cf56"},"source":["# brown corpus의 첫 10개의 단어\n","print(list(brown.words())[:10]) #words 함수를 말뭉치의 토큰으로 접근이 가능하다."],"execution_count":17,"outputs":[{"output_type":"stream","text":["['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', 'Friday', 'an', 'investigation', 'of']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UWOkCSvuHQeJ","executionInfo":{"status":"ok","timestamp":1628642506361,"user_tz":-540,"elapsed":49,"user":{"displayName":"천영성","photoUrl":"","userId":"06905110897473075189"}}},"source":["def reverse_half(words: List[str], targets: List[str]):\n","    \"\"\"\n","    reverse half of the occurences of target words in `words` (in-place)\n","    :param words:\n","    :param targets\n","    :return:\n","    \"\"\"\n","    ### TODO 1 ###\n","    # 말뭉치에 나타나는 target words의 절반을 뒤집어준다.\n","    # car -> rac.\n","    # use random.sample()\n","    occ_idxs = [idx for idx,word in enumerate(words) if word in targets]\n","    sub_idxs = random.sample(occ_idxs,len(occ_idxs)//2) \n","    for idx in sub_idxs:\n","        words[idx] = \"\".join(reversed(words[idx]))\n","    ##############"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"7IeGUy-MkM5-","executionInfo":{"status":"ok","timestamp":1628642506361,"user_tz":-540,"elapsed":46,"user":{"displayName":"천영성","photoUrl":"","userId":"06905110897473075189"}}},"source":["CORPUS = \"actually, I actually like the way you actually speak. you actually seem to be a nice person.\"\n","words = CORPUS.split(\" \")\n","reverse_half(words,CORPUS)"],"execution_count":19,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BZYPkMgs1Dor"},"source":["- 예시:\n","- 입력: \n"]},{"cell_type":"code","metadata":{"id":"eYIsfu5nHdFt","executionInfo":{"status":"ok","timestamp":1628642506362,"user_tz":-540,"elapsed":46,"user":{"displayName":"천영성","photoUrl":"","userId":"06905110897473075189"}}},"source":["class Vocab:\n","    def __init__(self, words: List[str]):\n","        # 인덱스가 주어지면, 인덱스에 해당하는 어휘를 반환\n","        self.idx2word = list(set(words))\n","        # 어휘가 주어지면, 어휘에 해당하는 인덱스를 반환\n","        self.word2idx = {\n","            word: idx\n","            for idx, word in enumerate(self.idx2word)\n","        }\n","\n","    def __contains__(self, item: str):\n","        return item in self.idx2word\n","    def __str__(self) -> str:\n","        return str(self.idx2word)\n","    def __len__(self):\n","        return len(self.idx2word)"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p8EgdO27k2WE","executionInfo":{"status":"ok","timestamp":1628642506362,"user_tz":-540,"elapsed":45,"user":{"displayName":"천영성","photoUrl":"","userId":"06905110897473075189"}},"outputId":"51ab5a2f-7123-492d-b754-33d969fb4152"},"source":["vocab =  Vocab(words = [\"car\",\"car\",\"truck\",\"bicycle\"])\n","car_idx = vocab.word2idx[\"car\"]\n","print(vocab.idx2word[car_idx])\n","print(str(vocab))"],"execution_count":21,"outputs":[{"output_type":"stream","text":["car\n","['bicycle', 'truck', 'car']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"y9J5gOuLHfKI","executionInfo":{"status":"ok","timestamp":1628642506362,"user_tz":-540,"elapsed":41,"user":{"displayName":"천영성","photoUrl":"","userId":"06905110897473075189"}}},"source":["# stemmer, lemmatiser는 제가 구현했습니다 :)\n","def stem(words: List[str]):\n","    global stemmer\n","    for idx, word in enumerate(words):\n","        words[idx] = stemmer.stem(word)\n","\n","def lemmatise(words: List[str]):\n","    global lemmatiser\n","    for idx, word in enumerate(words):\n","        words[idx] = lemmatiser.lemmatize(word)"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GtUBt6jHlqOc","executionInfo":{"status":"ok","timestamp":1628642506363,"user_tz":-540,"elapsed":41,"user":{"displayName":"천영성","photoUrl":"","userId":"06905110897473075189"}},"outputId":"283861aa-aade-43b3-8282-a68ed97c1ce8"},"source":["print(words)\n","stem(words)\n","print(words)\n","\n","print(words)\n","lemmatise(words)\n","print(words)"],"execution_count":23,"outputs":[{"output_type":"stream","text":["['actually,', 'I', 'yllautca', 'like', 'eht', 'way', 'uoy', 'actually', 'speak.', 'uoy', 'actually', 'seem', 'ot', 'be', 'a', 'ecin', 'person.']\n","['actually,', 'I', 'yllautca', 'like', 'eht', 'way', 'uoy', 'actual', 'speak.', 'uoy', 'actual', 'seem', 'ot', 'be', 'a', 'ecin', 'person.']\n","['actually,', 'I', 'yllautca', 'like', 'eht', 'way', 'uoy', 'actual', 'speak.', 'uoy', 'actual', 'seem', 'ot', 'be', 'a', 'ecin', 'person.']\n","['actually,', 'I', 'yllautca', 'like', 'eht', 'way', 'uoy', 'actual', 'speak.', 'uoy', 'actual', 'seem', 'ot', 'be', 'a', 'ecin', 'person.']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RcADWzm-Hh9Y","executionInfo":{"status":"ok","timestamp":1628642506363,"user_tz":-540,"elapsed":37,"user":{"displayName":"천영성","photoUrl":"","userId":"06905110897473075189"}}},"source":["def build_count_comat(vocab: Vocab, windows: List[Tuple[str]]) -> np.ndarray:\n","    \"\"\"\n","    count the frequencies of the co-occurrences.\n","    # dtm. documents = vocab. terms = vocab.\n","    :param vocab:\n","    :param windows:\n","    :return:\n","    \"\"\"\n","\n","    num_words = len(vocab)\n","    comat = np.zeros(shape=(num_words, num_words))\n","    for window in tqdm(windows, desc=\"building count comat...\"):\n","        for term_1 in window:\n","            for term_2 in window:\n","                  ### TODO 2 ###\n","                  # use vocab.word2idx, 파이썬의 try-catch pattern, word in vocab\n","                  # 만약 term_1과 term_2 모두 어휘에 해당하는 단어라면, 해당 comat에서\n","                  # 해당 co-occurence를 +1 한다.\n","                  try:\n","                    term_1_idx = vocab.word2idx[term_1]\n","                    term_2_idx = vocab.word2idx[term_2]\n","                  except KeyError:\n","                    continue\n","                  else:\n","                    comat[term_1_idx,term_2_idx] += 1\n","                  ##############\n","    # set the diagonal to zero (useless)\n","    comat[range(num_words), range(num_words)] = 0\n","    ###########\n","    return comat"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qZJqC74FnZxV","executionInfo":{"status":"ok","timestamp":1628642506364,"user_tz":-540,"elapsed":36,"user":{"displayName":"천영성","photoUrl":"","userId":"06905110897473075189"}},"outputId":"323f4fcc-2fc8-450c-8fc8-f839d3863511"},"source":["print(vocab)\n","print(words)\n","vocab  = Vocab([\"like\",\"the\"])\n","windows = list(ngrams(words,2))\n","print(windows)\n","comat = build_count_comat(vocab,windows)\n","print(comat)"],"execution_count":25,"outputs":[{"output_type":"stream","text":["building count comat...: 100%|██████████| 16/16 [00:00<00:00, 57260.12it/s]"],"name":"stderr"},{"output_type":"stream","text":["['bicycle', 'truck', 'car']\n","['actually,', 'I', 'yllautca', 'like', 'eht', 'way', 'uoy', 'actual', 'speak.', 'uoy', 'actual', 'seem', 'ot', 'be', 'a', 'ecin', 'person.']\n","[('actually,', 'I'), ('I', 'yllautca'), ('yllautca', 'like'), ('like', 'eht'), ('eht', 'way'), ('way', 'uoy'), ('uoy', 'actual'), ('actual', 'speak.'), ('speak.', 'uoy'), ('uoy', 'actual'), ('actual', 'seem'), ('seem', 'ot'), ('ot', 'be'), ('be', 'a'), ('a', 'ecin'), ('ecin', 'person.')]\n","[[0. 0.]\n"," [0. 0.]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"G20GJFZ2Hjts","executionInfo":{"status":"ok","timestamp":1628642506364,"user_tz":-540,"elapsed":31,"user":{"displayName":"천영성","photoUrl":"","userId":"06905110897473075189"}}},"source":["def cluster_target_words(n_clusters, tfidf_mat: np.array, vocab: Vocab) -> List[List[str]]:\n","    \"\"\"\n","    K-means 알고리즘을 활용해서, 클러스터링을 진행합니다.\n","    \"\"\"\n","    clusters: List[List[str]] = [list() for _ in range(n_clusters)]  # a bucket to collect clusters\n","    k_means = KMeans(n_clusters=n_clusters, random_state=RAND_STATE)\n","    result = k_means.fit(tfidf_mat)\n","    for word_idx, cluster_idx in enumerate(result.labels_):\n","        word = vocab.idx2word[word_idx]\n","        # append the word to the cluster\n","        clusters[cluster_idx].append(word)\n","    return clusters"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"id":"d40WZcpbHlL4","executionInfo":{"status":"ok","timestamp":1628642506364,"user_tz":-540,"elapsed":30,"user":{"displayName":"천영성","photoUrl":"","userId":"06905110897473075189"}}},"source":["def eval_clusters(clusters: List[List[str]], targets: List[str], targets_reversed: List[str]) -> float:\n","    \"\"\"\n","    returns the accuracy.\n","    :param clusters:\n","    :param targets\n","    :param targets_reversed\n","    :return:\n","    \"\"\"\n","    pairs = list(zip(targets, targets_reversed))\n","    total = len(pairs)\n","    correct = 0\n","    ### TODO 3 ###\n","    # targets (반전하기전), target_reversed (반전 후)가 모두 같은 클러스터에 존재하는지\n","    # 확인해서, 같은 클러스터에 존재한다면 correct += 1.\n","    for pair in pairs:\n","      target,target_reversed = pair\n","      for cluster in clusters:\n","        if target in cluster and target_reversed in cluster:\n","          correct +=1 \n","    ##############\n","    return correct / total\n"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"9PKwTe5MHnCa","executionInfo":{"status":"ok","timestamp":1628642506365,"user_tz":-540,"elapsed":29,"user":{"displayName":"천영성","photoUrl":"","userId":"06905110897473075189"}}},"source":["def run_experiment(corpus_name: str,\n","                   lower_case: bool,\n","                   remove_stopwords: bool,\n","                   norm_mode: Optional[str],\n","                   window_size: int):\n","    if corpus_name == BROWN_NAME:\n","        # nltk에서 제공하는 함수\n","        corpus = brown\n","    elif corpus_name == PR2_NAME:\n","        corpus = product_reviews_2\n","    else:\n","        raise ValueError\n","    targets = TARGET_WORDS.split(\"\\n\")\n","    # 말뭉치에 있는 모든 단어 \n","    words: List[str] = list(corpus.words())\n","    # 이후에는 파라미터에 따라 말뭉치를 전처리.\n","    # --- case folding --- #\n","    if lower_case:\n","        words = [word.lower() for word in words]\n","    # --- stopwords filtering --- #\n","    if remove_stopwords:\n","        words = [word for word in words if word not in stopwords.words(\"english\")]\n","    # --- 정규화: stemming or lemmatisation --- #\n","    if norm_mode == \"stem\":\n","        # then.. you must stem the vocab.\n","        stem(words)  # stem words in-place\n","        stem(targets)\n","    elif norm_mode == \"lemmatise\":\n","        lemmatise(words)  # lemmatise words in-place\n","        lemmatise(targets)\n","    # --- ngrams 으로 맥락 윈도우 구축하기 --- #\n","    reverse_half(words, targets)  # for pseudo-eval\n","    windows = list(ngrams(words, window_size))\n","    # --- 어휘 구축하기 --- #\n","    targets_reversed = [\"\".join(reversed(target)) for target in targets]\n","    vocab = Vocab(words=targets + targets_reversed)\n","    # --- build a word2word co-occurrence matrix (dtm), where both documents & terms are target words --- #\n","    comat = build_count_comat(vocab, windows)\n","    # --- cluster the target words using their tfidf vectors --- #\n","    n_clusters = len(vocab) // 2\n","    clusters = cluster_target_words(n_clusters, comat, vocab)\n","    # --- evaluate the clusters;check if the reversed form is included in the same cluster --- #\n","    acc = eval_clusters(clusters, targets, targets_reversed)\n","    # --- 결과 리포트 --- #\n","    print(\"### REPORT ###\")\n","    print(\"vocab_size:{}, n_clusters:{}, lower_case: {}, remove_stopwords:{}, corpus_name:{}, stem_or_lemmatise:{}, window_size:{}\"\n","          .format(len(vocab), n_clusters, lower_case, remove_stopwords, corpus_name, norm_mode, window_size))\n","    pprinter = PrettyPrinter(compact=True)\n","    pprinter.pprint(clusters)\n","    print(\"accuracy:\", acc)"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"ID_p6p-nHr9j","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628642862699,"user_tz":-540,"elapsed":356362,"user":{"displayName":"천영성","photoUrl":"","userId":"06905110897473075189"}},"outputId":"5afb7eda-69f0-449d-aaf5-6479748c48b8"},"source":["  run_experiment(corpus_name=BROWN_NAME, lower_case=False, remove_stopwords=False, norm_mode=None,  window_size=8)\n","  # the effect of lemmatisation on the performance\n","  run_experiment(corpus_name=BROWN_NAME, lower_case=False, remove_stopwords=False, norm_mode=\"lemmatise\", window_size=8)\n","  # the effect of stemming on the performance\n","  run_experiment(corpus_name=BROWN_NAME, lower_case=False, remove_stopwords=False,  norm_mode=\"stem\", window_size=8)  # 이게 아마도 성능이 제일 좋을 겁니다.\n","  # the effect of case folding on the performance\n","  run_experiment(corpus_name=BROWN_NAME,  lower_case=True, remove_stopwords=False, norm_mode=\"stem\", window_size=8)\n","  # the effect of switching corpus on the performance\n","  run_experiment(corpus_name=PR2_NAME,  lower_case=False, remove_stopwords=False, norm_mode=\"stem\", window_size=8)\n","  # the effect of removing stopwords\n","  run_experiment(corpus_name=BROWN_NAME,  lower_case=False, remove_stopwords=True, norm_mode=\"stem\", window_size=8)"],"execution_count":29,"outputs":[{"output_type":"stream","text":["building count comat...: 100%|██████████| 1161185/1161185 [00:26<00:00, 43848.13it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["### REPORT ###\n","vocab_size:100, n_clusters:50, lower_case: False, remove_stopwords:False, corpus_name:brown, stem_or_lemmatise:None, window_size:8\n","[['nrettap', 'yranoitcid', 'mean', 'melborp'], ['they'], ['yeht'], ['course'],\n"," ['rehtegot'], ['yhw'], ['reason'], ['set'], ['got'], ['back'], ['why'],\n"," ['tog'], ['idea'], ['tnereffid'],\n"," ['general', 'answer', 'dda', 'result', 'esac', 'case'], ['kcab'],\n"," ['dnik', 'llac'], ['tes'], ['together'], ['rac'], ['ecalp'], ['part'],\n"," ['adbmal', 'arguments', 'register', 'tcejbo', 'machine', 'rotaulave',\n","  'argument', 'elpmis', 'noitcnuf', 'enihcam', 'abstraction', 'product',\n","  'function', 'pattern', 'rdc', 'cdr', 'rotarepo', 'add', 'address', 'using',\n","  'operator', 'process', 'retsiger', 'variable', 'retupmoc', 'tnemugra',\n","  'structure', 'stnemugra', 'erutcurts', 'zero', 'noitcartsba', 'gnisu', 'orez',\n","  'computer', 'evaluator', 'lambda', 'dictionary', 'elbairav', 'sserdda',\n","  'riap', 'pair', 'tcudorp'],\n"," ['nosaer'], ['metsys'], ['car'], ['different'], ['problem'], ['trap'],\n"," ['program'], ['tluser'], ['margorp'], ['order'], ['kind'], ['redro'],\n"," ['ralucitrap'], ['place'], ['rewsna'], ['actually'], ['ssecorp'], ['object'],\n"," ['system'], ['simple'], ['esruoc'], ['call'], ['lareneg'], ['yllautca'],\n"," ['particular'], ['aedi'], ['naem']]\n","accuracy: 0.38\n"],"name":"stdout"},{"output_type":"stream","text":["building count comat...: 100%|██████████| 1161185/1161185 [00:26<00:00, 44388.82it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["### REPORT ###\n","vocab_size:98, n_clusters:49, lower_case: False, remove_stopwords:False, corpus_name:brown, stem_or_lemmatise:lemmatise, window_size:8\n","[['particular'], ['they'], ['yeht'],\n"," ['object', 'adbmal', 'register', 'machine', 'rotaulave', 'argument', 'simple',\n","  'enihcam', 'abstraction', 'product', 'function', 'pattern', 'rdc', 'cdr',\n","  'rotarepo', 'address', 'using', 'operator', 'retsiger', 'yranoitcid',\n","  'retupmoc', 'erutcurts', 'dda', 'zero', 'noitcartsba', 'gnisu', 'orez',\n","  'computer', 'evaluator', 'lambda', 'dictionary', 'elbairav', 'sserdda',\n","  'riap', 'pair', 'tcudorp'],\n"," ['call'], ['mean', 'case'], ['got'], ['nosaer'], ['yhw'], ['kind'], ['kcab'],\n"," ['program'], ['rehtegot'], ['system'],\n"," ['answer', 'add', 'yllautca', 'llac', 'redro', 'esac'], ['back'], ['why'],\n"," ['tnereffid'], ['different'], ['metsys'], ['car'], ['together'], ['tog'],\n"," ['rac'], ['ecalp'], ['dnik'], ['problem'], ['melborp'], ['tcejbo', 'tluser'],\n"," ['reason'], ['idea'], ['naem'], ['trap'], ['ralucitrap'], ['process'],\n"," ['aedi'], ['margorp'], ['part'], ['set'], ['tes'], ['esruoc'], ['lareneg'],\n"," ['place'], ['rewsna'], ['order'], ['elpmis'],\n"," ['general', 'noitcnuf', 'nrettap', 'actually', 'variable', 'tnemugra',\n","  'structure', 'result'],\n"," ['ssecorp'], ['course']]\n","accuracy: 0.28\n"],"name":"stdout"},{"output_type":"stream","text":["building count comat...: 100%|██████████| 1161185/1161185 [00:26<00:00, 44032.45it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["### REPORT ###\n","vocab_size:98, n_clusters:49, lower_case: False, remove_stopwords:False, corpus_name:brown, stem_or_lemmatise:stem, window_size:8\n","[['tcudorp'], ['yeht'], ['they'], ['nrettap', 'evalu', 'structur', 'tupmoc'],\n"," ['order'], ['dnik', 'set'], ['use'], ['esu'],\n"," ['answer', 'rewsna', 'product', 'particular', 'sruoc', 'aedi', 'redro',\n","  'actual', 'esac', 'case'],\n"," ['nosaer'], ['htegot', 'togeth', 'llac'], ['whi'],\n"," ['iranoitcid', 'variabl', 'nihcam', 'lbairav', 'machin'], ['program'],\n"," ['differ'], ['metsys'], ['gener'], ['back'], ['reneg'], ['naem'], ['reffid'],\n"," ['system'], ['tluser'], ['mean'], ['repo'], ['call'], ['oper'], ['ssecorp'],\n"," ['got'], ['kcab'],\n"," ['adbmal', 'tsiger', 'argument', 'ralucitrap', 'comput', 'tcartsba',\n","  'abstract', 'regist', 'dictionari', 'pattern', 'lpmis', 'rdc', 'cdr', 'add',\n","  'ulave', 'address', 'tnemugra', 'simpl', 'dda', 'zero', 'orez', 'rutcurts',\n","  'lambda', 'sserdda', 'riap', 'pair'],\n"," ['kind'], ['ihw'], ['melborp'], ['ecalp'], ['tcejbo'], ['reason'], ['result'],\n"," ['problem'], ['object', 'margorp', 'trap'], ['noitcnuf', 'function'], ['tes'],\n"," ['process'], ['part'], ['idea'], ['place'], ['tog'], ['cours', 'lautca'],\n"," ['car', 'rac']]\n","accuracy: 0.36\n"],"name":"stdout"},{"output_type":"stream","text":["building count comat...: 100%|██████████| 1161185/1161185 [00:26<00:00, 44103.01it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["### REPORT ###\n","vocab_size:98, n_clusters:49, lower_case: True, remove_stopwords:False, corpus_name:brown, stem_or_lemmatise:stem, window_size:8\n","[['part'], ['yeht'],\n"," ['adbmal', 'tsiger', 'argument', 'iranoitcid', 'comput', 'tcartsba',\n","  'abstract', 'regist', 'dictionari', 'particular', 'pattern', 'variabl', 'rdc',\n","  'cdr', 'evalu', 'add', 'ulave', 'address', 'structur', 'tnemugra', 'simpl',\n","  'dda', 'lbairav', 'tupmoc', 'zero', 'machin', 'orez', 'rutcurts', 'lambda',\n","  'sserdda', 'riap', 'pair', 'esac'],\n"," ['they'], ['ecalp', 'sruoc', 'actual'], ['use'], ['back'], ['reason'],\n"," ['process', 'system'], ['whi'], ['esu'], ['got'], ['tog', 'htegot', 'togeth'],\n"," ['program'], ['reneg'], ['reffid'], ['repo'], ['tcudorp'], ['tcejbo'],\n"," ['mean'], ['differ'], ['product'], ['naem'], ['noitcnuf'], ['trap'],\n"," ['dnik', 'cours', 'set', 'melborp'], ['oper'], ['place'], ['metsys'],\n"," ['lautca'], ['nosaer'], ['gener'], ['result'], ['rac'],\n"," ['car', 'answer', 'rewsna', 'ralucitrap', 'lpmis', 'nrettap', 'aedi', 'case'],\n"," ['kcab'], ['ssecorp'], ['call', 'llac'], ['ihw'], ['margorp'], ['redro'],\n"," ['tluser'], ['problem'], ['idea', 'order'], ['nihcam'], ['tes'], ['kind'],\n"," ['function'], ['object']]\n","accuracy: 0.36\n"],"name":"stdout"},{"output_type":"stream","text":["building count comat...: 100%|██████████| 84612/84612 [00:01<00:00, 43684.96it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["### REPORT ###\n","vocab_size:98, n_clusters:49, lower_case: False, remove_stopwords:False, corpus_name:product_reviews_2, stem_or_lemmatise:stem, window_size:8\n","[['comput'],\n"," ['object', 'adbmal', 'tcejbo', 'tsiger', 'rewsna', 'argument', 'iranoitcid',\n","  'dnik', 'reason', 'noitcnuf', 'idea', 'tcartsba', 'abstract', 'regist',\n","  'dictionari', 'particular', 'pattern', 'rdc', 'nrettap', 'cdr', 'htegot',\n","  'evalu', 'ulave', 'address', 'order', 'process', 'structur', 'tnemugra',\n","  'tluser', 'lbairav', 'zero', 'sruoc', 'aedi', 'redro', 'machin', 'orez',\n","  'rutcurts', 'part', 'lambda', 'result', 'riap', 'place'],\n"," ['esu'], ['product'], ['yeht'], ['they'], ['lautca'], ['use'], ['program'],\n"," ['melborp'], ['llac'], ['reffid'], ['repo'], ['system'], ['metsys'], ['ihw'],\n"," ['trap', 'naem', 'mean', 'pair'], ['tupmoc'], ['oper'], ['kind'], ['problem'],\n"," ['kcab'], ['tcudorp'], ['set'], ['add'], ['simpl'], ['got'], ['tes'],\n"," ['answer'], ['margorp'], ['call'], ['back'], ['nihcam'], ['dda'], ['actual'],\n"," ['whi'], ['ecalp', 'car', 'function', 'variabl', 'case'], ['ralucitrap'],\n"," ['nosaer'], ['reneg'], ['lpmis'], ['differ'], ['tog'], ['esac'], ['rac'],\n"," ['ssecorp', 'sserdda'], ['gener'], ['cours'], ['togeth']]\n","accuracy: 0.32\n"],"name":"stdout"},{"output_type":"stream","text":["building count comat...: 100%|██████████| 727494/727494 [00:16<00:00, 43202.32it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["### REPORT ###\n","vocab_size:98, n_clusters:49, lower_case: False, remove_stopwords:True, corpus_name:brown, stem_or_lemmatise:stem, window_size:8\n","[['comput', 'actual'], ['cours', 'trap'],\n"," ['rewsna', 'ralucitrap', 'idea', 'lautca', 'particular', 'pattern', 'lpmis',\n","  'variabl', 'ulave', 'structur', 'simpl', 'nihcam', 'sruoc', 'aedi', 'machin',\n","  'rutcurts'],\n"," ['process'], ['esu'], ['noitcnuf', 'tes', 'esac', 'nosaer'], ['tog'], ['use'],\n"," ['metsys'], ['naem'], ['ecalp'], ['case'], ['repo'], ['reffid'], ['reneg'],\n"," ['oper'], ['differ'], ['product'], ['gener'], ['set'], ['tluser'], ['melborp'],\n"," ['program'], ['problem'], ['they'], ['yeht'], ['order'], ['llac'],\n"," ['ssecorp', 'tcudorp'], ['rac'], ['object'], ['tcejbo'], ['system'],\n"," ['adbmal', 'tsiger', 'argument', 'iranoitcid', 'tcartsba', 'abstract',\n","  'regist', 'dictionari', 'rdc', 'cdr', 'evalu', 'add', 'address', 'tnemugra',\n","  'dda', 'lbairav', 'tupmoc', 'zero', 'ihw', 'whi', 'orez', 'lambda', 'sserdda',\n","  'riap', 'pair'],\n"," ['call'], ['dnik'], ['got', 'car'], ['back'], ['redro'], ['mean'],\n"," ['htegot', 'togeth'], ['kcab'], ['function'], ['place'], ['answer'], ['part'],\n"," ['reason', 'nrettap', 'kind'], ['result'], ['margorp']]\n","accuracy: 0.36\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"V_IOES4-iB_u"},"source":["다음과 같은 결과가 나와야 합니다:\n","```\n","building count comat...: 100%|██████████| 1161185/1161185 [00:09<00:00, 119558.38it/s]\n","### REPORT ###\n","vocab_size:100, n_clusters:50, lower_case: False, remove_stopwords:False, corpus_name:brown, stem_or_lemmatise:None, window_size:8\n","[['redro'], ['yeht'], ['they'], ['program', 'yllautca'], ['rehtegot'],\n"," ['rotarepo', 'elpmis'], ['yhw'], ['reason'], ['llac'], ['got'], ['kcab'],\n"," ['tnereffid'], ['esruoc'], ['tes'], ['metsys'], ['different'], ['margorp'],\n"," ['back'], ['system'], ['course'], ['rac'], ['why'], ['kind'], ['nosaer'],\n"," ['together'], ['place'], ['tog'], ['ecalp'], ['ralucitrap'], ['order'],\n"," ['part'], ['aedi'],\n"," ['machine', 'retsiger', 'operator', 'computer', 'stnemugra', 'enihcam',\n","  'tcejbo', 'dda', 'arguments', 'variable', 'cdr', 'sserdda', 'address',\n","  'tcudorp', 'gnisu', 'noitcartsba', 'rdc', 'pair', 'abstraction', 'evaluator',\n","  'register', 'elbairav', 'retupmoc', 'yranoitcid', 'dictionary', 'zero',\n","  'structure', 'erutcurts', 'rotaulave', 'adbmal', 'nrettap', 'orez',\n","  'function', 'product', 'result', 'lambda', 'noitcnuf', 'riap', 'melborp',\n","  'argument'],\n"," ['set'], ['dnik'], ['object'], ['ssecorp'], ['trap'], ['problem'], ['process'],\n"," ['tluser'], ['lareneg'], ['call', 'actually', 'esac', 'add'], ['car'],\n"," ['using'], ['particular'],\n"," ['naem', 'case', 'pattern', 'tnemugra', 'answer', 'general', 'idea'],\n"," ['simple'], ['mean'], ['rewsna']]\n","accuracy: 0.32\n","building count comat...: 100%|██████████| 1161185/1161185 [00:09<00:00, 120675.27it/s]\n","### REPORT ###\n","vocab_size:98, n_clusters:49, lower_case: False, remove_stopwords:False, corpus_name:brown, stem_or_lemmatise:lemmatise, window_size:8\n","[['rac'], ['yeht'],\n"," ['machine', 'rotarepo', 'retsiger', 'operator', 'computer', 'enihcam', 'dda',\n","  'simple', 'pattern', 'actually', 'variable', 'cdr', 'sserdda', 'address',\n","  'tcudorp', 'gnisu', 'noitcartsba', 'rdc', 'pair', 'abstraction', 'evaluator',\n","  'object', 'register', 'using', 'elbairav', 'retupmoc', 'yranoitcid',\n","  'dictionary', 'tnemugra', 'zero', 'structure', 'erutcurts', 'rotaulave',\n","  'adbmal', 'orez', 'function', 'product', 'lambda', 'noitcnuf', 'riap',\n","  'argument'],\n"," ['they'], ['case'], ['why'], ['tes'], ['esruoc'], ['got'], ['reason'],\n"," ['back'], ['kcab'], ['car'], ['tog'], ['aedi'],\n"," ['call', 'tcejbo', 'redro', 'yllautca'], ['rehtegot', 'together'], ['system'],\n"," ['different'], ['nosaer'], ['tnereffid'], ['melborp'], ['order'], ['metsys'],\n"," ['kind'], ['problem'], ['set'], ['idea'], ['place'],\n"," ['answer', 'rewsna', 'tluser'], ['ecalp'], ['part'], ['margorp'], ['process'],\n"," ['yhw'], ['mean'], ['dnik'], ['naem'], ['ralucitrap'], ['elpmis'],\n"," ['esac', 'particular', 'add', 'llac'], ['trap'], ['lareneg'], ['ssecorp'],\n"," ['result'], ['program'], ['nrettap'], ['course'], ['general']]\n","accuracy: 0.42\n","building count comat...: 100%|██████████| 1161185/1161185 [00:09<00:00, 120763.07it/s]\n","### REPORT ###\n","vocab_size:98, n_clusters:49, lower_case: False, remove_stopwords:False, corpus_name:brown, stem_or_lemmatise:stem, window_size:8\n","[['tes'], ['yeht'], ['they'], ['ulave', 'dda', 'answer', 'ralucitrap', 'lpmis'],\n"," ['reason'], ['esu'], ['tog', 'htegot'], ['sruoc', 'dnik'], ['whi'],\n"," ['set', 'idea'], ['reffid'],\n"," ['case', 'pattern', 'comput', 'tnemugra', 'structur', 'nrettap', 'evalu',\n","  'simpl', 'rac', 'tupmoc'],\n"," ['use'], ['result', 'tluser'], ['program', 'trap'], ['gener'], ['naem'],\n"," ['reneg'], ['problem'], ['call'], ['differ'], ['system'], ['kcab'], ['ihw'],\n"," ['redro', 'esac', 'particular', 'rewsna', 'actual'], ['metsys'], ['oper'],\n"," ['back'], ['process', 'product'], ['object'], ['function', 'noitcnuf'],\n"," ['ssecorp'], ['place'], ['cours', 'lautca'], ['part'], ['aedi'],\n"," ['got', 'togeth', 'llac'], ['car'], ['mean'], ['tcejbo'], ['margorp'],\n"," ['ecalp'], ['kind'], ['repo'],\n"," ['machin', 'tsiger', 'regist', 'variabl', 'cdr', 'sserdda', 'abstract',\n","  'address', 'rdc', 'pair', 'tcartsba', 'iranoitcid', 'rutcurts', 'nihcam',\n","  'zero', 'adbmal', 'add', 'orez', 'lbairav', 'lambda', 'riap', 'argument',\n","  'dictionari'],\n"," ['melborp'], ['tcudorp'], ['nosaer'], ['order']]\n","accuracy: 0.28\n","building count comat...: 100%|██████████| 1161185/1161185 [00:09<00:00, 120562.30it/s]\n","### REPORT ###\n","vocab_size:98, n_clusters:49, lower_case: True, remove_stopwords:False, corpus_name:brown, stem_or_lemmatise:stem, window_size:8\n","[['machin', 'variabl', 'esac', 'nihcam', 'lbairav', 'simpl'], ['yeht'],\n"," ['they'], ['htegot', 'togeth'], ['use'], ['program'], ['case', 'object'],\n"," ['nosaer'], ['ihw'], ['aedi', 'ralucitrap', 'lpmis', 'rewsna', 'dnik'],\n"," ['gener'], ['mean'], ['got', 'tog'], ['back'],\n"," ['pattern', 'particular', 'rutcurts', 'structur', 'idea', 'nrettap', 'result'],\n"," ['differ'], ['cours', 'redro'], ['reneg'], ['esu'], ['tluser'],\n"," ['tsiger', 'regist', 'ulave', 'dda', 'cdr', 'sserdda', 'abstract', 'address',\n","  'rdc', 'pair', 'tcartsba', 'iranoitcid', 'comput', 'answer', 'tnemugra',\n","  'zero', 'adbmal', 'add', 'evalu', 'orez', 'lambda', 'noitcnuf', 'riap',\n","  'argument', 'rac', 'tupmoc', 'dictionari'],\n"," ['melborp'], ['reffid'], ['metsys'], ['kind'], ['whi'], ['set', 'place'],\n"," ['oper'], ['part'], ['margorp', 'process'], ['tcudorp'], ['trap'], ['naem'],\n"," ['kcab'], ['order'], ['call'], ['reason'], ['ssecorp'],\n"," ['sruoc', 'lautca', 'actual'], ['car'], ['repo'], ['product'], ['llac'],\n"," ['problem'], ['tcejbo'], ['system'], ['tes'], ['ecalp'], ['function']]\n","accuracy: 0.4\n","building count comat...: 100%|██████████| 84612/84612 [00:00<00:00, 119893.90it/s]\n","### REPORT ###\n","vocab_size:98, n_clusters:49, lower_case: False, remove_stopwords:False, corpus_name:product_reviews_2, stem_or_lemmatise:stem, window_size:8\n","[['simpl'], ['redro', 'process', 'answer'],\n"," ['cours', 'machin', 'tsiger', 'regist', 'aedi', 'ulave', 'tcejbo', 'dda',\n","  'pattern', 'cdr', 'abstract', 'address', 'rdc', 'pair', 'tcartsba', 'object',\n","  'particular', 'ecalp', 'htegot', 'iranoitcid', 'rutcurts', 'tnemugra',\n","  'structur', 'zero', 'idea', 'reneg', 'adbmal', 'nrettap', 'evalu', 'orez',\n","  'lbairav', 'result', 'dnik', 'lambda', 'part', 'noitcnuf', 'riap', 'order',\n","  'argument', 'dictionari', 'tluser'],\n"," ['esu'], ['use'], ['repo'], ['they'], ['yeht'], ['llac'], ['actual'],\n"," ['problem'], ['tes'], ['tcudorp'], ['system'], ['call'], ['melborp'],\n"," ['comput'], ['mean', 'case', 'car', 'nihcam', 'function'], ['metsys'], ['set'],\n"," ['tupmoc'], ['program'], ['ihw'], ['margorp'], ['kcab'], ['product'], ['got'],\n"," ['oper'], ['back'], ['differ'], ['nosaer'], ['whi'], ['lautca'], ['sruoc'],\n"," ['tog'], ['kind'], ['add'], ['ssecorp'], ['rac'], ['esac'], ['sserdda'],\n"," ['naem', 'togeth', 'trap', 'rewsna'], ['reffid'], ['gener'], ['ralucitrap'],\n"," ['lpmis'], ['reason'], ['place'], ['variabl']]\n","accuracy: 0.3\n","building count comat...: 100%|██████████| 727494/727494 [00:06<00:00, 120995.04it/s]\n","### REPORT ###\n","vocab_size:98, n_clusters:49, lower_case: False, remove_stopwords:True, corpus_name:brown, stem_or_lemmatise:stem, window_size:8\n","[['ihw', 'tsiger', 'regist', 'variabl', 'ulave', 'dda', 'cdr', 'sserdda',\n","  'abstract', 'whi', 'rdc', 'pair', 'tcartsba', 'iranoitcid', 'answer',\n","  'tnemugra', 'ralucitrap', 'structur', 'zero', 'adbmal', 'add', 'orez',\n","  'lpmis', 'rewsna', 'lbairav', 'lambda', 'riap', 'simpl', 'argument', 'tupmoc',\n","  'dictionari'],\n"," ['reneg'], ['melborp'], ['set'], ['tluser'], ['got', 'car', 'tog'], ['esu'],\n"," ['use'], ['metsys'], ['kcab'], ['gener'], ['repo'], ['ecalp'],\n"," ['sruoc', 'esac'], ['object'], ['program'], ['reffid'], ['system'],\n"," ['ssecorp'], ['mean'], ['kind', 'case', 'reason'], ['llac'], ['differ'],\n"," ['trap'], ['process'], ['yeht'], ['result'], ['noitcnuf'], ['dnik'], ['rac'],\n"," ['order'], ['product'], ['redro'], ['margorp'], ['tcudorp'], ['naem'],\n"," ['problem'], ['tes'], ['part'], ['call'], ['back'], ['they'],\n"," ['machin', 'aedi', 'pattern', 'address', 'particular', 'rutcurts', 'comput',\n","  'lautca', 'nihcam', 'nrettap', 'evalu', 'actual', 'nosaer'],\n"," ['idea'], ['oper'], ['htegot', 'togeth'], ['cours'], ['tcejbo', 'function'],\n"," ['place']]\n","accuracy: 0.38\n","```"]},{"cell_type":"markdown","metadata":{"id":"TNXu7O3wHwH8"},"source":["## 다음의 질문에 답하세요.\n","\n",">  stemming을 했을 때, 안했을 때 성능의 차이? 이유는?\n","\n",">  case folding을 했을때, 안 했을 때 성능의 차이? 이유는?\n","\n",">  말뭉치가 BROWN 일 때, 아닐 때, 성능의 차이? 이유는?"]},{"cell_type":"code","metadata":{"id":"5sXbF36RIgEq","executionInfo":{"status":"ok","timestamp":1628642862700,"user_tz":-540,"elapsed":34,"user":{"displayName":"천영성","photoUrl":"","userId":"06905110897473075189"}}},"source":[""],"execution_count":29,"outputs":[]}]}