{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CopyDeepLearning18.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPgKgulk+mSOvs9Suc+J+6C"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"8tt_vGu6jl2Q"},"source":["##데이터 증폭 버전 이진분류 학습기 "]},{"cell_type":"code","metadata":{"id":"6l9x1_VYjX8u"},"source":["%run /content/MathUtils.ipynb\n","%run /content/abalone_model.ipynb\n","\n","#main 함수\n","def binary_classification_exec(epoch_count,mb_size,report,train_ratio,val_ratio,ad_just_ratio):\n","  binary_load_dataset(ad_just_ratio) #증폭을 할것인지 말것인지 결정하는 ad_just_ratio\n","  init_param()\n","  train_metrics_mean_row,val_metrics_row,test_metrics = train_and_test(epoch_count,mb_size,report,train_ratio,val_ratio)\n","  return train_metrics_mean_row,val_metrics_row,test_metrics\n","\n","#binary_load_dataset data set making 1.amplication 2.not amplication\n","def binary_load_dataset(ad_just_ratio):\n","  pulsars = []\n","  stars = []\n","\n","  with open('/content/pulsar_stars.csv') as csvfile:\n","    csvreader = csv.reader(csvfile)\n","    next(csvreader)\n","\n","    for row in csvreader:\n","      if row[8] == '1':\n","        pulsars.append(row)\n","      else:\n","        stars.append(row)\n","    \n","    global data,input_cnt,output_cnt\n","    input_cnt= 8 \n","    output_cnt =1  #독립변수 8개 종속변수 1개 \n","\n","    star_cnt,pulsar_cnt = len(stars),len(pulsars)\n","'''\n","    for row in csvreader:\n","    rows.append(row) #data 한줄 한줄 저장\n","    \n","    global data, input_cnt,output_cnt\n","\n","    input_cnt,output_cnt = 8,1 #독립 변수  = 8 종속변수 = 1\n","    data = np.asarray(rows , dtype = 'float32') #문자화 데이터 숫자화를 위한 타입 변경'''\n","\n","    if ad_just_ratio: #증폭을 수행할떄 수행하면 데이터의 개수는 똑같아서 stars * 2 배 로 가능 \n","      data = np.zeros([star_cnt * 2,9])\n","      data[0:star_cnt,:] = np.asarray(stars,dtype = 'float32')\n","\n","      for n in range(star_cnt):\n","        data[star_cnt+n] = np.asarray(pulsars[n%pulsar_cnt],dtype = 'float32') \n","        #index 가 증가할때 마다 다음 데이터를 전체 유성 데이터로 나눠서 순환하는 데이터 시스템을 초기화 \n","\n","      \n","    else:\n","      data = np.zeros([star_cnt+pulsar_cnt , 9]) #전체 크기에 맞는 데이터를 zeros 로 할당\n","      data[0:star_cnt,:] = np.asarray(stars,dtype='float32') #0~starcnt 까지는 별 데이터로 초기화 \n","      data[star_cnt:,:] = np.asarray(pulsars,dtype = 'float32') #starcnt ~  끝까지 는 중성자 별로 초기화 \n","\n","#weight 와 bias 초기화 \n","def init_param():\n","  global weight,bias \n","  weight = np.random.normal(RND_MEAN,RND_STD,size = [input_cnt,output_cnt])\n","  bias = np.zeros([output_cnt])\n","\n","#safe_div = zero divistion 문제 해결\n","def safe_div(p,q):\n","  p,q = float(p),float(q)\n","  if np.abs(q)<1.0e-20: #만약 이수가 0이라면\n","    return np.sign(p) #p의 값을 양수 0 음수 일떄  1 0 -1 로 처리 하라 \n","  return p/q\n","\n","#eval_accuracy_numpy 혼합 행렬로 만들어진 4가지 의 metrics score 를 return \n","def eval_accuracy_numpy(output,y):\n","  #예측값과 실제값에 대한 초기화 참/거짓\n","  est_yes = np.greater(output,0)\n","  ans_yes = np.greater(y,0.5)\n","\n","  est_no = np.logical_not(est_yes)\n","  ans_no = np.logical_not(ans_yes)\n","\n","  #tp/tn/fp/fn 구하기\n","  tp = np.sum(np.logical_and(est_yes,ans_yes))\n","  tn = np.sum(np.logical_and(est_no,ans_no))\n","  fp = np.sum(np.logical_and(est_yes,ans_no))\n","  fn = np.sum(np.logical_and(est_no,ans_yes))\n","\n","  #acc/precision/recall/f1 score 구하기 \n","  accuracy = safe_div(tp+tn,tp+tn+fp+fn)\n","  precision = safe_div(tp,tp+fp)\n","  recall = safe_div(tp,tp+fn)\n","  f1 = 2 * safe_div(recall*precision , recall+precision)\n","\n","  return [accuracy,precision,recall,f1]\n","#arrange_data = data 미니배치 스탭 카운트 \n","def arrange_data(mb_size,train_ratio,val_ratio):\n","  global shuffle_map , val_begin_index,test_begin_index\n","  shuffle_map = np.arange(data.shape[0])\n","  np.random.shuffle(shuffle_map)\n","\n","  mini_batch_step_count = int(data.shape[0] * train_ratio) //mb_size\n","  val_begin_index = mini_batch_step_count * mb_size\n","  test_begin_index = int(val_begin_index + (val_ratio * data.shape[0]))\n","\n","  return mini_batch_step_count\n","\n","#get train,test,val\n","def get_train_data(mb_size,n):\n","\n","  from_idx = mb_size * n #미니 배치 사이즈의 시작\n","  to_idx = mb_size * (n+1) #끝\n","\n","  train_data = data[shuffle_map[from_idx:to_idx]]\n","\n","  return train_data[:,:-output_cnt], train_data[:,-output_cnt:]\n","\n","def get_val_data():\n","  val_data = data[shuffle_map[val_begin_index:test_begin_index]]\n","  return val_data[:,:-output_cnt] , val_data[:,-output_cnt:]\n","\n","def get_test_data():\n","  test_data = data[shuffle_map[test_begin_index:]]\n","  return test_data[:,:-output_cnt] , test_data[:,-output_cnt:]\n","\n","#순전파 연산 \n","##foward_neuralnet ,forward_postproc\n","\n","def forward_neuralnet(x):\n","  y_hat = np.matmul(x,weight)+bias \n","  return y_hat,x\n","\n","def forward_postproc(output,y):\n","  CEE = sigmoid_cross_entropy_with_logits(y,output)\n","  loss = np.mean(CEE)\n","\n","  return loss,[y,output,CEE]\n","\n","\n","def relu(x):\n","  return np.maximum(x,0)\n","\n","def sigmoid_cross_entropy_with_logits(z,x):\n","  return relu(x) - x * z + np.log(1+np.exp(-np.abs(x))) \n","\n","#역전파 연산 \n","## backprop_postproc , backprop_neuralnet\n","def backprop_neuralnet(G_output,x):\n","  global weight,bias #경사 하강법 진행을 위해 \n","\n","  x_transpose = x.transpose()\n","  G_w = np.matmul(x_transpose ,G_output)\n","  G_b = np.sum(G_output,axis = 0)\n","\n","  weight -= LEARNING_RATE * G_w\n","  bias -= LEARNING_RATE * G_b\n","\n","\n","def backprop_postproc(aux_pp_y_output_CEE):\n","  y,output,CEE = aux_pp_y_output_CEE\n","\n","  g_loss_entropy = 1.0 / np.prod(CEE.shape)\n","  g_entropy_output = sigmoid_cross_entropy_with_logits_derv(y,output)\n","\n","  G_output = g_loss_entropy * g_entropy_output\n","  return G_output\n","\n","def sigmoid(x):\n","  return np.exp(-relu(x))/(1.0+np.exp(-np.abs(x)))\n","\n","def sigmoid_cross_entropy_with_logits_derv(z,x):\n","  return - z + sigmoid(x)\n","\n","def run_train(x,y):\n","  y_hat,aux_nn_x = forward_neuralnet(x)\n","  loss,aux_pp_y_output_CEE = forward_postproc(y_hat,y)\n","  acc = eval_accuracy_numpy(y_hat,y)\n","\n","  G_output = backprop_postproc(aux_pp_y_output_CEE)\n","  backprop_neuralnet(G_output,aux_nn_x)\n","  return loss,acc\n","\n","def run_test(x,y):\n","  y_hat,_ = forward_neuralnet(x)\n","  loss,_ = forward_postproc(y_hat,y)\n","  acc = eval_accuracy_numpy(y_hat,y)\n","  return loss,acc\n","\n","def train_and_test(epoch_count,mb_size,report,train_ratio,val_ratio):\n","  mini_batch_step_count = arrange_data(mb_size,train_ratio,val_ratio)\n","  test_x,test_y = get_test_data()\n","  val_x,val_y = get_val_data()\n","\n","  losses_mean_row = [] #loss 값 평균 저장 \n","  val_loss_row = []\n","\n","  for epoch in range(epoch_count):\n","    losses = [] #loss 값 저장 \n","\n","    for n in range(mini_batch_step_count):\n","      train_x,train_y = get_train_data(mb_size,n)\n","\n","      loss,_ = run_train(train_x,train_y)\n","      losses.append(loss)\n","\n","    val_loss,val_acc = run_test(val_x,val_y)\n","    val_loss_row.append(val_loss)\n","\n","    if report>0 and (epoch+1) % report == 0:\n","            print(\"Epoch {} : Train - Loss = {:.3f} / Val - Loss = {:.3f}, Acc = {:.3f}, Precision = {:.3f}, Recall = {:.3f}, F1 = {:.3F}\".\\\n","                  format(epoch+1, np.mean(losses), val_loss, val_acc[0], val_acc[1], val_acc[2], val_acc[3]))\n","    \n","    losses_mean = np.mean(losses)\n","    losses_mean_row.append(losses_mean)\n","\n","  test_loss,test_acc = run_test(test_x,test_y)\n","\n","  print(\"\\n\",\"=\" * 50, 'Final Test', '=' * 50)\n","  print('\\nTest Acc = {:.3f}, Precision = {:.3f}, Recall = {:.3f}, F1 = {:.3F}'.\\\n","        format(test_acc[0], test_acc[1], test_acc[2], test_acc[3]))\n","  print('\\nLoss = {:.3f}'.format(test_loss))\n","\n","  return [losses_mean_row],[val_loss_row],[test_loss,test_acc]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qLgecFEtjkBw"},"source":["binary_load_dataset(ad_just_ratio=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u2v9P0IgkfDb","executionInfo":{"status":"ok","timestamp":1629098855073,"user_tz":-540,"elapsed":250,"user":{"displayName":"천영성","photoUrl":"","userId":"06905110897473075189"}},"outputId":"a1ea9db8-67ad-4898-ba2b-d313376bbc4e"},"source":["train_x,train_y = get_train_data(6,0)\n","val_x,val_y = get_val_data()\n","test_x,test_y = get_test_data()\n","\n","print(train_x.shape)\n","print(train_y.shape)\n","print(val_x.shape)\n","print(val_y.shape)\n","print(test_x.shape)\n","print(test_y.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(6, 8)\n","(6, 1)\n","(6503, 8)\n","(6503, 1)\n","(6509, 8)\n","(6509, 1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rf6oz5ZXyepG","executionInfo":{"status":"ok","timestamp":1629098916109,"user_tz":-540,"elapsed":246,"user":{"displayName":"천영성","photoUrl":"","userId":"06905110897473075189"}},"outputId":"5cc7a6a7-c611-4b16-b181-71d075a8a234"},"source":["loss,acc = run_train(train_x,train_y)\n","val_loss,val_acc = run_test(val_x,val_y)\n","test_loss,test_acc = run_test(test_x,test_y)\n","\n","print(loss,acc)\n","print(val_loss,val_acc)\n","print(test_loss,test_acc)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["532.1588842329131 [0.3333333333333333, 0.0, 0.0, 0.0]\n","504.2782198159135 [0.5069967707212056, 0.0, 0.0, 0.0]\n","508.48401400331153 [0.5039176524811799, 0.0, 0.0, 0.0]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uUm-hPWAusaM"},"source":["mini_batch_step_count = arrange_data(6,0.6,0.2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UwYhXqbeu6dP"},"source":["init_param()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tVbMENKF1RZw","executionInfo":{"status":"ok","timestamp":1629099544458,"user_tz":-540,"elapsed":13010,"user":{"displayName":"천영성","photoUrl":"","userId":"06905110897473075189"}},"outputId":"5ccd123e-7316-4d27-e0ec-37d3db97c1cf"},"source":["train_metrics_mean_row, val_metrics_row, test_metrics = binary_classification_exec(epoch_count = 100, \n","                                                                                   mb_size     = 32, \n","                                                                                   report      = 1, \n","                                                                                   train_ratio = 0.6, \n","                                                                                   val_ratio   = 0.2,\n","                                                                                   ad_just_ratio = True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1 : Train - Loss = 64877.655 / Val - Loss = 128191.972, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 2 : Train - Loss = 195491.199 / Val - Loss = 256430.193, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 3 : Train - Loss = 326104.833 / Val - Loss = 384668.414, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 4 : Train - Loss = 456718.466 / Val - Loss = 512906.635, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 5 : Train - Loss = 587332.100 / Val - Loss = 641144.856, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 6 : Train - Loss = 717945.733 / Val - Loss = 769383.077, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 7 : Train - Loss = 848559.367 / Val - Loss = 897621.298, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 8 : Train - Loss = 979173.000 / Val - Loss = 1025859.518, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 9 : Train - Loss = 1109786.634 / Val - Loss = 1154097.739, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 10 : Train - Loss = 1240400.267 / Val - Loss = 1282335.960, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 11 : Train - Loss = 1371013.901 / Val - Loss = 1410574.181, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 12 : Train - Loss = 1501627.534 / Val - Loss = 1538812.402, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 13 : Train - Loss = 1632241.168 / Val - Loss = 1667050.623, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 14 : Train - Loss = 1762854.801 / Val - Loss = 1795288.844, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 15 : Train - Loss = 1893468.435 / Val - Loss = 1923527.065, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 16 : Train - Loss = 2024082.068 / Val - Loss = 2051765.286, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 17 : Train - Loss = 2154695.702 / Val - Loss = 2180003.507, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 18 : Train - Loss = 2285309.335 / Val - Loss = 2308241.728, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 19 : Train - Loss = 2415922.969 / Val - Loss = 2436479.949, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 20 : Train - Loss = 2546536.602 / Val - Loss = 2564718.170, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 21 : Train - Loss = 2677150.236 / Val - Loss = 2692956.391, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 22 : Train - Loss = 2807763.869 / Val - Loss = 2821194.612, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 23 : Train - Loss = 2938377.503 / Val - Loss = 2949432.833, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 24 : Train - Loss = 3068991.136 / Val - Loss = 3077671.054, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 25 : Train - Loss = 3199604.770 / Val - Loss = 3205909.275, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 26 : Train - Loss = 3330218.403 / Val - Loss = 3334147.496, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 27 : Train - Loss = 3460832.037 / Val - Loss = 3462385.717, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 28 : Train - Loss = 3591445.670 / Val - Loss = 3590623.937, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 29 : Train - Loss = 3722059.304 / Val - Loss = 3718862.158, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 30 : Train - Loss = 3852672.937 / Val - Loss = 3847100.379, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 31 : Train - Loss = 3983286.571 / Val - Loss = 3975338.600, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 32 : Train - Loss = 4113900.204 / Val - Loss = 4103576.821, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 33 : Train - Loss = 4244513.838 / Val - Loss = 4231815.042, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 34 : Train - Loss = 4375127.471 / Val - Loss = 4360053.263, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 35 : Train - Loss = 4505741.105 / Val - Loss = 4488291.484, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 36 : Train - Loss = 4636354.738 / Val - Loss = 4616529.705, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 37 : Train - Loss = 4766968.372 / Val - Loss = 4744767.926, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 38 : Train - Loss = 4897582.005 / Val - Loss = 4873006.147, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 39 : Train - Loss = 5028195.639 / Val - Loss = 5001244.368, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 40 : Train - Loss = 5158809.272 / Val - Loss = 5129482.589, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 41 : Train - Loss = 5289422.906 / Val - Loss = 5257720.810, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 42 : Train - Loss = 5420036.539 / Val - Loss = 5385959.031, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 43 : Train - Loss = 5550650.173 / Val - Loss = 5514197.252, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 44 : Train - Loss = 5681263.806 / Val - Loss = 5642435.473, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 45 : Train - Loss = 5811877.440 / Val - Loss = 5770673.694, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 46 : Train - Loss = 5942491.073 / Val - Loss = 5898911.915, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 47 : Train - Loss = 6073104.707 / Val - Loss = 6027150.136, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 48 : Train - Loss = 6203718.340 / Val - Loss = 6155388.356, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 49 : Train - Loss = 6334331.974 / Val - Loss = 6283626.577, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 50 : Train - Loss = 6464945.607 / Val - Loss = 6411864.798, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 51 : Train - Loss = 6595559.241 / Val - Loss = 6540103.019, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 52 : Train - Loss = 6726172.874 / Val - Loss = 6668341.240, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 53 : Train - Loss = 6856786.508 / Val - Loss = 6796579.461, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 54 : Train - Loss = 6987400.141 / Val - Loss = 6924817.682, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 55 : Train - Loss = 7118013.775 / Val - Loss = 7053055.903, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 56 : Train - Loss = 7248627.408 / Val - Loss = 7181294.124, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 57 : Train - Loss = 7379241.042 / Val - Loss = 7309532.345, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 58 : Train - Loss = 7509854.675 / Val - Loss = 7437770.566, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 59 : Train - Loss = 7640468.309 / Val - Loss = 7566008.787, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 60 : Train - Loss = 7771081.942 / Val - Loss = 7694247.008, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 61 : Train - Loss = 7901695.576 / Val - Loss = 7822485.229, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 62 : Train - Loss = 8032309.209 / Val - Loss = 7950723.450, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 63 : Train - Loss = 8162922.843 / Val - Loss = 8078961.671, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 64 : Train - Loss = 8293536.476 / Val - Loss = 8207199.892, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 65 : Train - Loss = 8424150.110 / Val - Loss = 8335438.113, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 66 : Train - Loss = 8554763.743 / Val - Loss = 8463676.334, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 67 : Train - Loss = 8685377.377 / Val - Loss = 8591914.555, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 68 : Train - Loss = 8815991.010 / Val - Loss = 8720152.775, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 69 : Train - Loss = 8946604.644 / Val - Loss = 8848390.996, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 70 : Train - Loss = 9077218.277 / Val - Loss = 8976629.217, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 71 : Train - Loss = 9207831.911 / Val - Loss = 9104867.438, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 72 : Train - Loss = 9338445.544 / Val - Loss = 9233105.659, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 73 : Train - Loss = 9469059.178 / Val - Loss = 9361343.880, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 74 : Train - Loss = 9599672.811 / Val - Loss = 9489582.101, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 75 : Train - Loss = 9730286.445 / Val - Loss = 9617820.322, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 76 : Train - Loss = 9860900.078 / Val - Loss = 9746058.543, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 77 : Train - Loss = 9991513.712 / Val - Loss = 9874296.764, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 78 : Train - Loss = 10122127.345 / Val - Loss = 10002534.985, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 79 : Train - Loss = 10252740.979 / Val - Loss = 10130773.206, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 80 : Train - Loss = 10383354.612 / Val - Loss = 10259011.427, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 81 : Train - Loss = 10513968.246 / Val - Loss = 10387249.648, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 82 : Train - Loss = 10644581.879 / Val - Loss = 10515487.869, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 83 : Train - Loss = 10775195.513 / Val - Loss = 10643726.090, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 84 : Train - Loss = 10905809.146 / Val - Loss = 10771964.311, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 85 : Train - Loss = 11036422.780 / Val - Loss = 10900202.532, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 86 : Train - Loss = 11167036.413 / Val - Loss = 11028440.753, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 87 : Train - Loss = 11297650.047 / Val - Loss = 11156678.974, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 88 : Train - Loss = 11428263.680 / Val - Loss = 11284917.195, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 89 : Train - Loss = 11558877.314 / Val - Loss = 11413155.415, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 90 : Train - Loss = 11689490.947 / Val - Loss = 11541393.636, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 91 : Train - Loss = 11820104.581 / Val - Loss = 11669631.857, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 92 : Train - Loss = 11950718.214 / Val - Loss = 11797870.078, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 93 : Train - Loss = 12081331.848 / Val - Loss = 11926108.299, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 94 : Train - Loss = 12211945.481 / Val - Loss = 12054346.520, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 95 : Train - Loss = 12342559.115 / Val - Loss = 12182584.741, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 96 : Train - Loss = 12473172.748 / Val - Loss = 12310822.962, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 97 : Train - Loss = 12603786.382 / Val - Loss = 12439061.183, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 98 : Train - Loss = 12734400.015 / Val - Loss = 12567299.404, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 99 : Train - Loss = 12865013.649 / Val - Loss = 12695537.625, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","Epoch 100 : Train - Loss = 12995627.282 / Val - Loss = 12823775.846, Acc = 0.505, Precision = 0.505, Recall = 1.000, F1 = 0.671\n","\n"," ================================================== Final Test ==================================================\n","\n","Test Acc = 0.500, Precision = 0.500, Recall = 1.000, F1 = 0.666\n","\n","Loss = 12887789.244\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":487},"id":"AXB__IHXUxEq","executionInfo":{"status":"error","timestamp":1629425573704,"user_tz":-540,"elapsed":476,"user":{"displayName":"천영성","photoUrl":"","userId":"06905110897473075189"}},"outputId":"ad13d68d-03ed-4209-e609-95dc412714a5"},"source":["age = [10,30,20,40,90,70,60]\n","gender =['M',\"F\",'M','F','M','F','M']\n","\n","import pandas as pd \n","\n"],"execution_count":5,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mcreate_block_manager_from_blocks\u001b[0;34m(blocks, axes)\u001b[0m\n\u001b[1;32m   1670\u001b[0m                 blocks = [\n\u001b[0;32m-> 1671\u001b[0;31m                     \u001b[0mmake_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1672\u001b[0m                 ]\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mmake_block\u001b[0;34m(values, placement, klass, ndim, dtype)\u001b[0m\n\u001b[1;32m   2743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2744\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplacement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, values, placement, ndim)\u001b[0m\n\u001b[1;32m    130\u001b[0m             raise ValueError(\n\u001b[0;32m--> 131\u001b[0;31m                 \u001b[0;34mf\"Wrong number of items passed {len(self.values)}, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m                 \u001b[0;34mf\"placement implies {len(self.mgr_locs)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Wrong number of items passed 1, placement implies 2","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-fcee5e8f1170>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgender\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'gender'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'age'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    521\u001b[0m                     \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m                     \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_ndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m                 \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36minit_ndarray\u001b[0;34m(values, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0mblock_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcreate_block_manager_from_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mcreate_block_manager_from_blocks\u001b[0;34m(blocks, axes)\u001b[0m\n\u001b[1;32m   1679\u001b[0m         \u001b[0mblocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"values\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1680\u001b[0m         \u001b[0mtot_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1681\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mconstruction_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtot_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Shape of passed values is (7, 1), indices imply (7, 2)"]}]}]}